Directory structure:
‚îî‚îÄ‚îÄ heiko-hotz-project-horizon/
    ‚îú‚îÄ‚îÄ README.md
    ‚îú‚îÄ‚îÄ GETTING_STARTED.md
    ‚îú‚îÄ‚îÄ LICENSE
    ‚îú‚îÄ‚îÄ requirements.txt
    ‚îú‚îÄ‚îÄ .env.example
    ‚îú‚îÄ‚îÄ app/
    ‚îÇ   ‚îú‚îÄ‚îÄ live_server.py
    ‚îÇ   ‚îî‚îÄ‚îÄ static/
    ‚îÇ       ‚îú‚îÄ‚îÄ adk-websocket-api.js
    ‚îÇ       ‚îú‚îÄ‚îÄ index.html
    ‚îÇ       ‚îú‚îÄ‚îÄ styles.css
    ‚îÇ       ‚îú‚îÄ‚îÄ audio/
    ‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ audio-recorder.js
    ‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ audio-recording-worklet.js
    ‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ audio-streamer.js
    ‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ audioworklet-registry.js
    ‚îÇ       ‚îî‚îÄ‚îÄ utils/
    ‚îÇ           ‚îî‚îÄ‚îÄ utils.js
    ‚îú‚îÄ‚îÄ assets/
    ‚îú‚îÄ‚îÄ common/
    ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
    ‚îÇ   ‚îú‚îÄ‚îÄ types.py
    ‚îÇ   ‚îú‚îÄ‚îÄ client/
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ card_resolver.py
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ client.py
    ‚îÇ   ‚îú‚îÄ‚îÄ server/
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ server.py
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ task_manager.py
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ utils.py
    ‚îÇ   ‚îî‚îÄ‚îÄ utils/
    ‚îÇ       ‚îú‚îÄ‚îÄ in_memory_cache.py
    ‚îÇ       ‚îî‚îÄ‚îÄ push_notification_auth.py
    ‚îú‚îÄ‚îÄ host_agent/
    ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
    ‚îÇ   ‚îú‚îÄ‚îÄ agent.py
    ‚îÇ   ‚îî‚îÄ‚îÄ tools.py
    ‚îú‚îÄ‚îÄ mcp_servers/
    ‚îÇ   ‚îî‚îÄ‚îÄ stock_mcp_server/
    ‚îÇ       ‚îî‚îÄ‚îÄ server.py
    ‚îú‚îÄ‚îÄ specialist_agents/
    ‚îÇ   ‚îî‚îÄ‚îÄ stock_info_agent/
    ‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
    ‚îÇ       ‚îú‚îÄ‚îÄ __main__.py
    ‚îÇ       ‚îú‚îÄ‚îÄ agent.py
    ‚îÇ       ‚îî‚îÄ‚îÄ task_manager.py
    ‚îî‚îÄ‚îÄ tests/
        ‚îî‚îÄ‚îÄ test_a2a_stock_client.py

================================================
FILE: README.md
================================================
# Project Horizon

## Exploring the Future of Interoperable, Multimodal AI Agent Systems

---
![Project Horizon Banner](assets/project-horizon.png)

---

## Overview

**Project Horizon explores the future of collaborative, multimodal AI agent systems.** It investigates how sophisticated, responsive, and interoperable agents can be built by integrating cutting-edge agent development frameworks and open communication protocols. This proof-of-concept demonstrates the powerful synergy between **Google's Agent Development Kit (ADK)** (leveraging the **Gemini Live API** for real-time interaction), the **Agent2Agent (A2A) protocol**, and the **Model Context Protocol (MCP)**.

![High-Level Architecture](assets/high-level-architecture.png)

This project serves as a reference implementation and a testbed for:

*   Integrating diverse agent frameworks and tools.
*   Implementing real-time, interactive user experiences (voice, video, text) using ADK's `run_live` powered by the Gemini Live API.
*   Establishing standardized communication patterns between independent agents (A2A).
*   Enabling agents to securely interact with external tools and data sources (MCP).
*   Exploring advanced agent architectures, design patterns, and evaluation techniques.

**Project Horizon aims to capture and demonstrate the future of agent interactions, providing technical implementations, architectural blueprints, and practical design patterns for building the next generation of AI applications.**

## Potential & Vision

Project Horizon is more than just a demonstration of a single capability; it's a foundation for exploring the future of collaborative AI:

*   **Interoperability Blueprint:** Provides a concrete example of how systems built with different frameworks (ADK, potentially LangChain/CrewAI via A2A/MCP wrappers) can communicate using open standards.
*   **Modular Agent Design:** Demonstrates the benefits of breaking down complex tasks into specialized agents communicating via A2A.
*   **Secure Tool Integration:** Showcases MCP as a standardized, potentially more secure way for agents to access external capabilities compared to direct API calls or embedding tool logic within the agent itself.
*   **Multimodal Interaction:** Leverages ADK `run_live` for cutting-edge, real-time voice and potentially video interactions.
*   **Design Pattern Exploration:** Serves as a platform to implement and compare different agent architectures (e.g., hierarchical delegation, parallel execution via A2A, sequential workflows combining A2A and MCP calls).
*   **Foundation for Asynchronicity:** While starting synchronous, the architecture is designed to evolve towards handling asynchronous tasks, long-running operations, and push notifications using A2A/MCP capabilities.

**Ultimately, Project Horizon aims to be a valuable resource for developers seeking to build robust, scalable, and interoperable multi-agent systems.**

## Core Technologies Showcased

*   **[Google Agent Development Kit (ADK)](https://google.github.io/adk-docs/):** Utilized for the primary user-facing "Host Agent", providing the `run_live` framework for agent orchestration and multimodal communication management.
*   **[Gemini Live API](https://ai.google.dev/gemini-api/docs/live):** Enables the low-latency, bidirectional, streaming voice (and potentially video) interactions with the Gemini model, powering the real-time user experience within ADK's `run_live`.
*   **[Agent2Agent Protocol (A2A)](https://google.github.io/A2A/):** The open standard used for communication and task delegation between the ADK Host Agent and backend "Specialist Agents". Enables interoperability between potentially different agent implementations.
*   **[Model Context Protocol (MCP)](https://modelcontextprotocol.io/):** The open standard allowing Specialist Agents (acting as MCP Clients) to securely interact with dedicated "Tool Servers" (MCP Servers) that provide access to specific functionalities or data (e.g., fetching stock prices).

## Current Scenario Demonstrated (v0.1.1 - Synchronous Stock Lookup with Improved Init)

The proof-of-concept focuses on a clear, synchronous end-to-end flow: **Real-Time Stock Price Lookup**.

**User Interaction:**
The user interacts with the Host Agent via a simple web UI, primarily using voice input. They ask for the current price of a stock (e.g., *"What is the price of Microsoft?"*).

**Execution Flow:**

0.  **Server Startup & Initialization (FastAPI & ADK):**
    *   When `app/live_server.py` is started (e.g., via `python -m app.live_server`), the FastAPI application initializes.
    *   FastAPI's `@app.on_event("startup")` decorator triggers the `startup_event` asynchronous function.
    *   `startup_event` calls `await initialize_adk_system()`.
        *   `initialize_adk_system()` calls `await create_host_agent()` from `host_agent/agent.py`.
        *   `create_host_agent()` in turn calls `await initialize_specialist_agents_discovery()` from `host_agent/tools.py`. This function fetches the Agent Card(s) of configured specialist agents (e.g., StockInfoAgent) and caches their details.
        *   The `HostAgent` instance is then created, its system instruction dynamically populated with information about the discovered specialist agents.
        *   Finally, the global ADK `Runner` instance within `live_server.py` is initialized with this fully configured `HostAgent`.
    *   Only after `initialize_adk_system()` completes does the FastAPI server begin accepting WebSocket connections and HTTP requests.

1.  **Input (ADK Live):** The frontend captures user audio and streams it via WebSocket to the ADK Live Server (`app/live_server.py`'s `/ws/{session_id}` endpoint).
2.  **Host Agent Processing (ADK):** The `live_server` (now with an initialized `Runner`) passes the input to the ADK `Runner` managing the `HostAgent`. The `HostAgent` (using a Live API compatible Gemini model) processes the audio/text input. Guided by its dynamic system prompt (which includes descriptions of discovered specialists like "StockInfoAgent\_A2A"), it identifies the user's intent and the stock ticker symbol (e.g., "MSFT").
3.  **Tool Invocation (ADK -> A2A Client):** The `HostAgent`'s LLM decides to use the `delegate_task_to_specialist` tool. It provides the `specialist_agent_name` (e.g., "StockInfoAgent\_A2A") and `query_payload` (e.g., "MSFT") as arguments. This tool acts as an A2A Client.
4.  **Delegation (A2A Request):** The `delegate_task_to_specialist` tool (in `host_agent/tools.py`) looks up the "StockInfoAgent\_A2A" in its `DISCOVERED_SPECIALIST_AGENTS` cache, retrieves its A2A endpoint URL (from the Agent Card), constructs an A2A `tasks/send` request containing the ticker symbol, and sends it via HTTP POST to the `StockInfoAgent`.
5.  **Task Reception (A2A Server):** The `StockInfoAgent` (`specialist_agents/stock_info_agent/__main__.py`), acting as an A2A Server, receives the HTTP request and parses the A2A task.
6.  **ADK Agent Execution (within A2A Server):** The `StockInfoTaskManager`'s `on_send_task` method is invoked. This method instantiates the ADK `stock_info_agent` (using `create_agent_with_mcp_tools` from `specialist_agents/stock_info_agent/agent.py`). `create_agent_with_mcp_tools` in turn initializes its `MCPToolset` by launching the `StockToolServer` (`mcp_servers/stock_mcp_server/server.py`) as a subprocess and captures the necessary `exit_stack` for cleanup. The Task Manager then creates and starts a temporary ADK `Runner` for this specialist ADK agent instance.
7.  **MCP Tool Call (via ADK Agent & Toolset):** The temporary ADK `Runner` executes the `stock_info_agent`. The agent's LLM processes the input query (e.g., "What is the stock price for MSFT?") and decides to use the `get_current_stock_price` tool (which was loaded from the MCP server). The agent's `MCPToolset` handles establishing the stdio connection and sending the actual MCP `tools/call` request to the running `StockToolServer` subprocess.
8.  **Tool Execution (MCP Server):** The `StockToolServer`, acting as an MCP Server (using FastMCP), receives the request via stdin, executes the `get_current_stock_price` function (which uses the `finnhub` library), and gets the stock data.
9.  **MCP Response (stdio):** The `StockToolServer` sends the result (price/currency dictionary or error) back as an MCP JSON-RPC response via stdout.
10. **ADK Agent Receives Tool Result & Task Manager Extracts Result:** The `MCPToolset` within the specialist ADK agent receives the MCP response, parses it, and the `Runner` yields it as a `FunctionResponse` event. The `StockInfoTaskManager`'s `on_send_task` method, iterating through these events, extracts the stock data dictionary. Once the `Runner`'s execution loop finishes, the `finally` block in `on_send_task` calls `await exit_stack.aclose()`, terminating the `StockToolServer` subprocess.
11. **Task Completion (A2A Response):** The `StockInfoTaskManager` formats the extracted stock data (or error) into an A2A Artifact (within a `Task` object marked as COMPLETED or FAILED) and sends it back as the HTTP response to the Host Agent's A2A Client tool.
12. **Tool Result (A2A Client -> ADK):** The `delegate_task_to_specialist` tool in the `HostAgent` receives the A2A HTTP response, parses the result/artifact, and returns the dictionary to the ADK `Runner`.
13. **Final Response Generation (ADK):** The `HostAgent` receives the tool result dictionary. Its LLM formulates a natural language response (e.g., "Microsoft is trading at $XXX.XX USD.").
14. **Audio Output (ADK Live):** ADK synthesizes the text response into audio using the configured Live API model/voice.
15. **Streaming Output (ADK Live -> UI):** The `live_server` streams the audio chunks via WebSocket back to the user interface, where it is played back in real-time.

![Flow](assets/flow.png)

**This phase successfully validates the core integration points between ADK Live, A2A (with dynamic agent card discovery), and MCP over stdio in a synchronous workflow.**

## Getting Started

For detailed setup, execution, and testing instructions for each component, please refer to the comprehensive [Getting Started Guide](./GETTING_STARTED.md).

### Prerequisites

*   Python (>= 3.9 required by MCP, >= 3.11 recommended for latest ADK/async features)
*   `pip` (Python package installer)
*   Git
*   Access to Google Cloud / Google AI Studio (for Gemini API Key/Credentials)
*   An API key for a Gemini model supporting the Live API (e.g., `gemini-2.0-flash-exp`).
*   Basic understanding of ADK, A2A, and MCP concepts.
*   Familiarity with `asyncio` and web frameworks (FastAPI/Starlette).

### Installation

1.  **Clone the Repository:**
    ```bash
    git clone <your-repo-url>
    cd project-horizon
    ```
2.  **Set up Virtual Environment:**
    ```bash
    python -m venv .venv
    source .venv/bin/activate  # Linux/macOS
    # .venv\Scripts\activate  # Windows
    ```
3.  **Install Dependencies:**
    ```bash
    pip install -r requirements.txt
    ```

### Configuration (`.env`)

1.  **Copy the Example:** In the project root, copy the `.env.example` file to a new file named `.env`.
    ```bash
    cp .env.example .env
    ```
2.  **Edit `.env`:** Open the newly created `.env` file and populate it with your specific configuration values. Refer to the comments within `.env.example` (and replicated below) for guidance on each variable.

Key variables you will need to set:
*   `GOOGLE_GENAI_USE_VERTEXAI`: **Mandatory.** Must be set to `"True"` or `"False"` to determine the API authentication method.
*   If `GOOGLE_GENAI_USE_VERTEXAI="False"` (for Google AI Studio):
    *   `GOOGLE_API_KEY`: **Mandatory.** Your API key for Google AI Studio.
*   If `GOOGLE_GENAI_USE_VERTEXAI="True"` (for Vertex AI):
    *   `GOOGLE_CLOUD_PROJECT`: **Mandatory.** Your Google Cloud Project ID.
    *   `GOOGLE_CLOUD_LOCATION`: **Mandatory.** Your Google Cloud Project Location (e.g., `us-central1`).
*   `FINNHUB_API_KEY`: **Recommended.** Your Finnhub API key for stock data. If not provided, stock queries will use mock data.
*   `LIVE_SERVER_MODEL`: **Highly Recommended.** Specifies the Live API compatible model for the Host Agent. Defaults to "gemini-2.0-flash-live-001" if not set. Ensure the chosen model (either default or custom) is available and appropriate for your setup.
*   `LIVE_SERVER_HOST`: **Mandatory.** Host for the ADK Live Server (e.g., `127.0.0.1`). Essential for the UI to connect.
*   `LIVE_SERVER_PORT`: **Mandatory.** Port for the ADK Live Server (e.g., `8000`).
*   `SPECIALIST_AGENT_BASE_URLS`: **Mandatory.** Comma-separated list of base URLs for specialist A2A agents (e.g., `http://127.0.0.1:8001`). The Host Agent will fetch Agent Cards from these.
*   `STOCK_INFO_AGENT_A2A_SERVER_HOST`: **Mandatory** (e.g., `127.0.0.1`). Host for *running* the StockInfoAgent's A2A server.
*   `STOCK_INFO_AGENT_A2A_SERVER_PORT`: **Mandatory** (e.g., `8001`). Port for *running* the StockInfoAgent's A2A server.
*   `STOCK_INFO_AGENT_MODEL`: **Mandatory.** Model for the specialist agent (e.g., "gemini-2.0-flash-001").
*   `STOCK_MCP_SERVER_PATH`: **Mandatory** (e.g., `mcp_servers/stock_mcp_server/server.py`). Path to the MCP server script, used by the StockInfoAgent.
*   `MOCK_STOCK_API`: Set to `"True"` or `"False"` to enable/disable the mock stock API (Default is `FALSE`).


### Running the Demo

Execute the components in separate terminals from the project root directory (`project-horizon/`), ensuring your virtual environment is active in each.

1.  **Terminal 1: Start Specialist Agent (StockInfoAgent A2A Server)**
    ```bash
    python -m specialist_agents.stock_info_agent
    ```
    *Verify it starts listening on the correct port (e.g., 8001 as per `.env`) and uses the correct MCP server path.*

2.  **Terminal 2: Start ADK Live Server (Host Agent)**
    ```bash
    python -m app.live_server
    ```
    *Verify it starts, performs specialist agent discovery, and then listens on its port (e.g., 8000 as per `.env`). Check logs for discovery messages.*

3.  **Access UI:** Open your web browser to `http://<LIVE_SERVER_HOST>:<LIVE_SERVER_PORT>` (e.g., `http://127.0.0.1:8000`).

4.  **Interact:**
    *   Click "Connect".
    *   Click the Mic button, speak a stock request (e.g., "What is the price of Apple?").
    *   Click the Mic button again to stop recording.
    *   Listen for the audio response.
    *   Check the logs in both terminals to see the A2A and MCP interactions.
    *   Click "Stop" in the UI when finished.


## Future Plans / Roadmap

This PoC establishes the synchronous foundation. Future iterations aim to explore:

*   **Asynchronous A2A/MCP:** Implement non-blocking calls, potentially using A2A streaming or push notifications for long-running tool operations within the Specialist Agent -> MCP Server interaction.
*   **Parallel A2A Delegation:** Modify the Host Agent to delegate tasks to multiple Specialist Agents concurrently (e.g., fetch stock price AND company news simultaneously).
*   **MCP over HTTP/SSE:** Migrate the `StockToolServer` from stdio to http/sse transport, requiring security considerations (authentication middleware) for the Specialist Agent's MCP client connection.
*   **Advanced State Management:** Utilize ADK's persistent SessionService options (Database, Vertex AI) and explore state sharing patterns between agents.
*   **Error Handling & Resilience:** Implement more robust error handling, retries, and fallback mechanisms across all communication layers.
*   **Additional Specialist Agents & Tools:** Expand the system with more agents (e.g., NewsAgent, PortfolioAgent) and corresponding MCP Tool Servers.
*   **ADK Evaluation:** Integrate ADK's evaluation framework (`adk eval`) to measure performance and accuracy.
*   **UI Enhancements:** Improve the frontend to better visualize multi-agent activity, tool calls, and potentially handle more complex inputs/outputs.

## üìú License

This project is licensed under the Apache License 2.0. See the [LICENSE](./LICENSE) file.

## ü§ù Contributing & Disclaimer

This is a personal project by [Heiko Hotz](https://github.com/heiko-hotz) to explore Gemini capabilities. Suggestions and feedback are welcome via Issues or Pull Requests.

**This project is developed independently and does not reflect the views or efforts of Google.**


================================================
FILE: GETTING_STARTED.md
================================================
# Getting Started

This guide provides detailed instructions on how to set up, run, and test the various components of Project Horizon.

## 1. Running and Testing the Stock MCP Server

The Stock MCP Server (`StockToolServer`) is responsible for fetching stock price information using the `finnhub` library (previously used `yfinance`). It communicates using the Model Context Protocol (MCP) over standard input/output (stdio).

### Prerequisites

*   Ensure you have followed the main project [Installation steps](./README.md#installation) from the `README.md`, especially installing dependencies from `requirements.txt`. This will make the `mcp` command-line tools available.
*   Activate your Python virtual environment:
    ```bash
    source .venv/bin/activate  # Linux/macOS
    # .venv\Scripts\activate  # Windows
    ```
*   **Finnhub API Key (Optional but Recommended):** To get real stock data, you'll need a Finnhub API key. If not provided, the server will use mock data.
    * Register for a free API key at [Finnhub.io](https://finnhub.io/)
    * Add the key to your `.env` file: `FINNHUB_API_KEY=your_api_key_here`

### A. Running the Stock MCP Server Independently

While the Specialist Agent normally starts this server as a subprocess, you can run it directly for testing or development.

1.  **Navigate to the project root directory:**
    ```bash
    cd /path/to/your/project-horizon # Replace with your actual project path
    ```
2.  **Run the server script:**
    ```bash
    python mcp_servers/stock_mcp_server/server.py
    ```
    If successful, the server will start and wait for MCP requests on its standard input. You won't see any immediate output until it receives a request. To stop it, you'd typically press `Ctrl+C` if you ran it directly in a terminal, but for testing with `mcp inspector`, the inspector will manage its lifecycle.

### B. Testing the Stock MCP Server with `mcp inspector`

The `mcp dev` command is the recommended way to test your Python-based MCP server. It starts your server script and concurrently launches the `@modelcontextprotocol/inspector`, a web-based UI for interacting with MCP servers.

**Additional Prerequisites for `mcp dev` / `@modelcontextprotocol/inspector`:**
*   **Node.js and npm/npx:** The `@modelcontextprotocol/inspector` is an npm package. `mcp dev` will typically handle its download via `npx` if it's not already available. Ensure you have Node.js installed, which includes npm (Node Package Manager) and npx (Node Package Execute).

1.  **Open a terminal** in the project root directory, with your Python virtual environment activated.

2.  **Run `mcp dev`:**
    Execute the following command, pointing to your MCP server script:
    ```bash
    mcp dev mcp_servers/stock_mcp_server/server.py
    ```
    *   **First-time use:** `mcp dev` (via `npx`) might ask for permission to download and install `@modelcontextprotocol/inspector` if it's the first time or if there's an update. For example:
        ```
        Need to install the following packages:
        @modelcontextprotocol/inspector@0.12.0
        Ok to proceed? (y)
        ```
        Type `y` and press Enter.
    *   Once started, you will see output indicating your Python server is running, a proxy server is operational, and the URL for the inspector. For example:
        ```
        INFO - MCP_SERVER - Initializing FastMCP server...
        ‚öôÔ∏è Proxy server listening on port 6277
        üîç MCP Inspector is up and running at http://127.0.0.1:6274 üöÄ
        ```
        *(Note: Port numbers and exact logging may vary)*

    *(Advanced Note: The `@modelcontextprotocol/inspector` can also be invoked directly using `npx @modelcontextprotocol/inspector python mcp_servers/stock_mcp_server/server.py`. However, for this project, using `mcp dev` is simpler as it manages both the server and inspector.)*

3.  **Using the MCP Inspector Web UI:**
    *   Open the Inspector URL provided in your terminal (e.g., `http://127.0.0.1:6274`). The `mcp dev` command should automatically connect the Inspector to your running `StockToolServer`.
    *   **Initial Connection:**
        *   Ideally, you'll be taken directly to a connected interface. However, if you were to encounter an initial screen asking you to manually configure the connection (similar to the image below), this would typically be for manual setups. With `mcp dev`, this screen (`assets/mcp-inspector-1.png`) should be bypassed.

            *Initial MCP Inspector Connection Screen (manual setup):*
            [![MCP Inspector Initial Connection Screen](assets/mcp-inspector-1.png)](assets/mcp-inspector-1.png)

    *   **Navigating the Connected Inspector:**
        *   Once connected, you'll see an interface with a connection pane on the left (showing server status, logs, and history) and main interaction tabs in the center.
        *   The **Resources Tab** (shown below, `assets/mcp-inspector-2.png`) lists data resources from the server. For the `StockToolServer`, which mainly provides tools, this tab might not show much specific content but illustrates the general layout once connected. The "History" section at the bottom will show initialization calls.

            *MCP Inspector - Resources Tab (example of a connected view):*
            [![MCP Inspector Resources Tab](assets/mcp-inspector-2.png)](assets/mcp-inspector-2.png)

        *   **Testing with the Tools Tab:**
            *   The primary tab for testing the `StockToolServer` is the **Tools Tab**.
            *   Select it, and you should see the `get_current_stock_price` tool listed.
            *   Click on `get_current_stock_price`. You can then input a `ticker_symbol` (e.g., "AAPL") and click "Run Tool", as illustrated below (`assets/mcp-inspector-3.png`).
            *   The results will appear in the "Tool Result" section, showing the JSON response from the server.

            *MCP Inspector - Tools Tab (calling get_current_stock_price and viewing results):*
            [![MCP Inspector Tool Call and Result](assets/mcp-inspector-3.png)](assets/mcp-inspector-3.png)

    *   **Further Details:**
        *   The MCP Inspector has many other features for in-depth debugging and interaction with MCP servers, including detailed views for prompts, server notifications, and more.
        *   For a comprehensive understanding of all its capabilities, please refer to the official **[MCP Inspector Documentation](https://modelcontextprotocol.io/docs/tools/inspector)**.

4.  **Goal of Testing:**
    Verify that the `get_current_stock_price` tool functions correctly. Call it with a valid stock ticker and check if the response contains the expected data structure (price, currency, symbol). Test with a mock symbol if `MOCK_STOCK_API` is enabled to see the mock data.

5.  **Stopping the Server and Inspector:**
    *   To stop the `StockToolServer` and the `mcp dev` proxy/inspector, go back to your terminal where you ran the `mcp dev` command and press `Ctrl+C`.

This confirms that your `StockToolServer` is working correctly and can respond to MCP requests via the `mcp dev` environment. The next steps in this guide will cover running the other components that interact with this server. 

## 2. Running and Testing the Specialist Agent (StockInfoAgent A2A Server)

The `StockInfoAgent` is a specialist agent responsible for handling stock information requests. It acts as an Agent-to-Agent (A2A) server, receiving tasks from the main Host Agent. Internally, it uses its own ADK agent instance, which in turn utilizes the `StockToolServer` (via MCP) to fetch actual stock data. This specialist agent launches and manages the `StockToolServer` as a subprocess.

### Prerequisites

*   **Virtual Environment:** Ensure your Python virtual environment (`.venv`) is activated:
    ```bash
    source .venv/bin/activate  # Linux/macOS
    # .venv\Scripts\activate  # Windows
    ```
*   **`.env` Configuration:** Your `.env` file in the project root must be correctly configured with the following key variables for the `StockInfoAgent`:
    *   `STOCK_INFO_AGENT_A2A_SERVER_HOST`: The host address the A2A server will bind to (e.g., `127.0.0.1`).
    *   `STOCK_INFO_AGENT_A2A_SERVER_PORT`: The port the A2A server will listen on (e.g., `8001`).
    *   `STOCK_INFO_AGENT_MODEL`: The Gemini model to be used by the ADK agent within the specialist (e.g., `gemini-1.0-pro`).
    *   `STOCK_MCP_SERVER_PATH`: The relative path to the Stock MCP Server script (e.g., `mcp_servers/stock_mcp_server/server.py`), which this agent will run as a subprocess.
    *   `FINNHUB_API_KEY`: (Optional but recommended) Your Finnhub API key for real stock data. If not provided, mock data will be used.
    *   `GOOGLE_GENAI_USE_VERTEXAI`, and either `GOOGLE_API_KEY` (if `False`) or `GOOGLE_CLOUD_PROJECT`/`GOOGLE_CLOUD_LOCATION` (if `True`): For authenticating with the Gemini API for the internal ADK agent.
    *   *(Refer to `.env.example` for the full list and descriptions.)*
*   **MCP Server Not Running Separately:** You do not need to run the `StockToolServer` (from Section 1) independently. The `StockInfoAgent` will start it automatically as a subprocess.

### A. Running the Specialist Agent

1.  **Navigate to the project root directory** (if you aren't already there).
2.  **Run the agent script:**
    ```bash
    python -m specialist_agents.stock_info_agent
    ```
3.  **Expected Output:**
    You should see log messages indicating the A2A server is starting, followed by confirmation that it's listening on the configured host and port. It will also typically log the initialization of its internal ADK agent and the launching of the `StockToolServer` subprocess.
    Key messages to look for (details and paths may vary):
    ```log
    INFO:__main__:Starting StockInfoAgent A2A Server...
    INFO:__main__:  Host: 127.0.0.1
    INFO:__main__:  Port: 8001
    INFO:__main__:  MCP Server Script Path: mcp_servers/stock_mcp_server/server.py
    INFO:specialist_agents.stock_info_agent.task_manager:StockInfoTaskManager initialized (ADK Runner Mode). Will use MCP server at: /path/to/your/project-horizon/mcp_servers/stock_mcp_server/server.py
    INFO:uvicorn:Uvicorn running on http://127.0.0.1:8001 (Press CTRL+C to quit)
    ```

### B. Testing the Specialist Agent

There are two main ways to test if the `StockInfoAgent` A2A server is running and correctly configured:
1.  Fetching its Agent Card via a web browser.
2.  Using the provided Python test client script for a functional test.

#### B.1. Fetching the Agent Card via Web Browser

The Agent Card provides metadata about the agent and its capabilities. It's located at a standard `.well-known` path.

1.  Ensure the `StockInfoAgent` (from section 2.A) is running in a separate terminal.
2.  **Open your web browser**.
3.  **Navigate to the Agent Card URL:**
    Use the host and port configured in your `.env` file for `STOCK_INFO_AGENT_A2A_SERVER_HOST` and `STOCK_INFO_AGENT_A2A_SERVER_PORT`.
    The standard path is `/.well-known/agent.json`.
    For example, if your agent is running on `http://127.0.0.1:8001`, the URL will be:
    ```
    http://127.0.0.1:8001/.well-known/agent.json
    ```
4.  **Expected Output:**
    Your browser should display a JSON response containing the agent's card. The exact content will depend on its configuration, but it will look something like this:
    ```json
    {
      "name": "StockInfoAgent",
      "description": "Provides current stock price information using the yfinance library via MCP.",
      "url": "http://127.0.0.1:8001",
      "provider": {
        "organization": "ProjectHorizon"
      },
      "version": "1.0.0",
      "capabilities": {
        "streaming": false,
        "pushNotifications": false,
        "stateTransitionHistory": false
      },
      "defaultInputModes": [
        "text/plain"
      ],
      "defaultOutputModes": [
        "application/json"
      ],
      "skills": [
        {
          "id": "get_stock_price_skill",
          "name": "Get Stock Price",
          "description": "Retrieves the current price and currency for a given stock ticker symbol.",
          "tags": [
            "finance",
            "stocks",
            "price lookup"
          ],
          "examples": [
            "What is the price of GOOGL?",
            "Stock price for MSFT"
          ],
          "outputModes": [
            "application/json"
          ]
        }
      ]
    }
    ```
    *   The presence of this JSON response in your browser indicates that the `StockInfoAgent` A2A server is running and accessible.
    *   This card is what the Host Agent will fetch during its own startup to discover and learn how to communicate with this specialist agent.

#### B.2. Using the A2A Test Client Script (`tests/test_a2a_stock_client.py`)

For a more functional test that simulates sending a task to the `StockInfoAgent`, you can use the `test_a2a_stock_client.py` script. This script acts as a dedicated test harness, performing an end-to-end check of the `StockInfoAgent`'s ability to receive a task, process it (which involves invoking its internal tool via MCP), and return a structured result.

**What the script does:**

1.  **Initialization:** 
    *   Takes a stock ticker symbol (e.g., `GOOGL`) as a mandatory command-line argument.
    *   Optionally accepts `--url` for the `StockInfoAgent` (defaulting to `http://127.0.0.1:8001`) and a `--session` ID (a new one is generated if not provided).
    *   It ensures the project root is in Python's `sys.path` to correctly import the `common` module.
2.  **A2A Client Setup:** 
    *   Creates an instance of `A2AClient` from `common.client.client`, configured to target the `StockInfoAgent`'s URL.
3.  **Task Construction:**
    *   Generates a unique `task_id`.
    *   Constructs an A2A `TaskSendParams` object. This is the standard way to define a task in A2A. The payload includes:
        *   The `task_id` and `sessionId`.
        *   A `Message` object with the `role` set to "user" and the provided stock symbol embedded within a `TextPart`. This simulates how the Host Agent would phrase the query to the specialist.
4.  **Sending the Task:**
    *   Sends the `TaskSendParams` (as a JSON payload) via an HTTP POST request to the `StockInfoAgent`'s `/tasks/send` A2A endpoint.
5.  **Processing the Response:**
    *   Asynchronously awaits the `SendTaskResponse` from the `StockInfoAgent`.
    *   Checks if the response indicates an error at the A2A level.
    *   If no immediate error, it inspects the `result` field of the response, which contains the final `Task` object from the specialist.
6.  **Verifying Task Outcome and Artifacts:**
    *   Logs the final `state` of the task (e.g., `COMPLETED`, `FAILED`).
    *   If the task `COMPLETED` successfully, it iterates through any `artifacts` attached to the task result. The `StockInfoAgent` is expected to return an artifact (e.g., named `stock_data` or similar) containing a `DataPart` with the actual stock price, currency, and symbol as a JSON object.
    *   The script then logs the content of these artifacts, allowing you to verify the data.
7.  **Error Handling:**
    *   Includes `try-except` blocks to gracefully handle potential issues like `ConnectionRefusedError` (if the agent isn't running), `A2AClientHTTPError` (for other HTTP issues), `A2AClientJSONError` (if the server's response is not valid JSON), and other unexpected exceptions.

**Why this script is useful:**

*   **Beyond a simple ping:** Unlike just fetching the Agent Card, this script tests the full request-processing pipeline of the `StockInfoAgent`.
*   **End-to-end validation:** It verifies that the agent can: 
    *   Correctly receive and parse an A2A task.
    *   Trigger its internal ADK agent logic.
    *   Successfully manage and communicate with its `StockToolServer` MCP subprocess.
    *   Receive the data back from the MCP server.
    *   Package the final result into the correct A2A `Artifact` format and send it back.
*   **Independent testing:** It allows you to confirm the `StockInfoAgent` is fully operational before attempting to integrate it with the main Host Agent and the UI, simplifying troubleshooting.

**How to run it:**

1.  Ensure the `StockInfoAgent` (from section 2.A) is running in a separate terminal.
2.  **Open a new terminal** in the project root directory, with your Python virtual environment activated:
    ```bash
    source .venv/bin/activate  # Linux/macOS
    # .venv\Scripts\activate  # Windows
    ```
3.  **Run the test script:**
    You need to provide a stock symbol as an argument. You can also specify the agent's URL and a session ID if needed (though defaults are provided).
    ```bash
    python tests/test_a2a_stock_client.py <STOCK_SYMBOL>
    ```
    For example, to test with the symbol "GOOGL":
    ```bash
    python tests/test_a2a_stock_client.py GOOGL
    ```
    To specify a different URL (if your agent isn't running on `http://127.0.0.1:8001`):
    ```bash
    python tests/test_a2a_stock_client.py GOOGL --url http://<your_agent_host>:<your_agent_port>
    ```
4.  **Expected Output:**
    The script will log its actions, including the generated task ID, session ID, and the full response from the A2A server. If successful, you should see logs indicating the task completed and the stock data artifact:
    ```
    INFO:     A2A_TEST_CLIENT - No session ID provided, generated one: test_session_xxxxxxxx
    INFO:     A2A_TEST_CLIENT - Creating A2A task yyyyyyyyyyyyyyyy for session test_session_xxxxxxxx with symbol 'GOOGL'
    INFO:     A2A_TEST_CLIENT - Sending task to A2A server at http://127.0.0.1:8001...
    INFO:     A2A_TEST_CLIENT - Received response from A2A server.
    INFO:     A2A_TEST_CLIENT - Task yyyyyyyyyyyyyyyy final state: COMPLETED
    INFO:     A2A_TEST_CLIENT - Task completed successfully.
    INFO:     A2A_TEST_CLIENT - Artifacts received:
    INFO:     A2A_TEST_CLIENT - - Artifact Name: stock_data
    INFO:     A2A_TEST_CLIENT -   DataPart Content: {
      "price": 2735.70, // Example price
      "currency": "USD",
      "symbol": "GOOGL"
    }
    ```
    If the agent is not running or there's an issue, the script will output error messages (e.g., connection refused, HTTP error, task failed).

    **Note on Mock Data:** If you haven't provided a Finnhub API key in your `.env` file, the tool will return mock data (price: 123.45). This is useful for testing without an API key, but not for production use.

4.  **Stopping the Specialist Agent:**
    *   Go back to the terminal where the `StockInfoAgent` is running and press `Ctrl+C`.
    *   This will also terminate the `StockToolServer` subprocess that it launched.

If you can successfully retrieve the Agent Card, your `StockInfoAgent` is likely set up correctly and ready to receive tasks. The next step in a full system test would be to run the Host Agent, which will interact with this Specialist Agent.

## 3. Running the ADK Live Server (Host Agent) and Performing an End-to-End Test

This final section explains how to run the main ADK Live Server, which hosts the "Host Agent". This agent orchestrates the user interaction (including voice via the Gemini Live API) and delegates tasks to specialist agents like the `StockInfoAgent` using A2A communication. This section will guide you through an end-to-end test of the entire system.

### Prerequisites

1.  **Specialist Agent MUST Be Running:**
    *   Before starting the ADK Live Server (Host Agent), ensure that the `StockInfoAgent` (Specialist Agent from Section 2.A) is already running in its own terminal. The Host Agent needs to discover and communicate with it.
2.  **Virtual Environment:**
    *   Ensure your Python virtual environment (`.venv`) is activated in the terminal where you will run the Live Server:
        ```bash
        source .venv/bin/activate  # Linux/macOS
        # .venv\Scripts\activate  # Windows
        ```
3.  **`.env` Configuration:**
    *   Your `.env` file in the project root must be correctly configured. Key variables for the ADK Live Server / Host Agent include:
        *   `LIVE_SERVER_HOST`: The host for the ADK Live Server (e.g., `127.0.0.1`).
        *   `LIVE_SERVER_PORT`: The port for the ADK Live Server (e.g., `8000`).
        *   `LIVE_SERVER_MODEL`: The Gemini model compatible with the Live API for the Host Agent (e.g., `gemini-1.5-flash-latest` or a specific Live-enabled version).
        *   `SPECIALIST_AGENT_BASE_URLS`: **Crucial.** A comma-separated list of base URLs for all specialist A2A agents that the Host Agent should discover. For the `StockInfoAgent`, if it's running on `http://127.0.0.1:8001`, this list should include that URL (e.g., `SPECIALIST_AGENT_BASE_URLS=http://127.0.0.1:8001`).
        *   `GOOGLE_GENAI_USE_VERTEXAI`, and corresponding `GOOGLE_API_KEY` or Google Cloud project details: For the Host Agent's Gemini API access.
        *   *(Refer to `.env.example` for the full list and descriptions.)*

### A. Running the ADK Live Server (Host Agent)

1.  **Navigate to the project root directory** (if you aren't already there).
2.  **Run the Live Server script:**
    ```bash
    python -m app.live_server
    ```
3.  **Expected Terminal Output:**
    You should see a series of log messages indicating:
    *   FastAPI application startup.
    *   Initialization of the ADK system (`initialize_adk_system()`).
    *   The Host Agent (`HostAgent`) being created.
    *   **Specialist Agent Discovery:** Crucially, logs showing the Host Agent attempting to fetch Agent Cards from the URLs specified in `SPECIALIST_AGENT_BASE_URLS`. For the `StockInfoAgent`, you should see messages indicating it successfully fetched and processed its card (e.g., `INFO:host_agent.tools:Discovered specialist agent: StockInfoAgent_A2A from http://127.0.0.1:8001/.well-known/agent.json`).
    *   The dynamic system prompt for the Host Agent being populated with information about discovered tools/specialists.
    *   Uvicorn server starting and listening on the configured `LIVE_SERVER_HOST` and `LIVE_SERVER_PORT`.
    Example (key messages, details may vary):
    ```log
    INFO:     Started server process [xxxxx]
    INFO:     Waiting for application startup.
    INFO:host_agent.agent:--- Loaded Environment Variables (HostAgent) ---
    INFO:app.live_server:Initializing ADK system...
    INFO:host_agent.agent:Creating HostAgent...
    INFO:host_agent.tools:Attempting to discover specialist agents from: ['http://127.0.0.1:8001']
    INFO:host_agent.tools:Fetching agent card from http://127.0.0.1:8001/.well-known/agent.json
    INFO:host_agent.tools:Discovered specialist agent: StockInfoAgent (StockInfoAgent_A2A) from http://127.0.0.1:8001/.well-known/agent.json
    INFO:host_agent.tools:Successfully discovered 1 specialist agents: ['StockInfoAgent']
    INFO:host_agent.agent:HostAgent created with dynamic system instructions including 1 discovered specialists.
    INFO:app.live_server:ADK system initialized successfully.
    INFO:     Application startup complete.
    INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)
    ```
    If you see errors related to specialist agent discovery, double-check that the `StockInfoAgent` is running and that `SPECIALIST_AGENT_BASE_URLS` in your `.env` file is correct.

### B. Performing an End-to-End Test via the UI

1.  **Access the Web UI:**
    Open your web browser and navigate to the address of your ADK Live Server (e.g., `http://127.0.0.1:8000`, based on your `LIVE_SERVER_HOST` and `LIVE_SERVER_PORT` settings).
2.  **Interact with the Host Agent:**
    *   Click the "Connect" button on the webpage to establish a WebSocket connection with the ADK Live Server.
    *   Click the microphone icon. Your browser may ask for permission to use your microphone; allow it.
    *   Speak your request clearly, for example: "What is the current price of Microsoft?" or "Stock price for AAPL".
    *   Click the microphone icon again to stop recording and send the audio to the server.
3.  **Observe the Result:**
    *   **Audio Response:** You should hear the Host Agent respond with the stock price information in a spoken voice.
    *   **Terminal Logs:** Check the terminals where both the `app.live_server` (Host Agent) and `specialist_agents.stock_info_agent` (Specialist Agent) are running.
        *   **Host Agent Logs:** You should see activity related to receiving your audio, transcribing it, the LLM deciding to use the `delegate_task_to_specialist` tool, the A2A request being sent to the `StockInfoAgent`, and the A2A response being received.
        *   **Specialist Agent Logs:** You should see it receiving an A2A task, logs from its internal ADK agent processing the request (which includes launching/communicating with its `StockToolServer` MCP subprocess), and sending the A2A task response back.
    This confirms the entire end-to-end flow: UI -> ADK Live Server (Host Agent) -> A2A -> Specialist Agent -> MCP -> `yfinance` -> MCP -> Specialist Agent -> A2A -> Host Agent -> UI (audio).

### C. Stopping the System

1.  **Stop the ADK Live Server (Host Agent):**
    *   Go to the terminal where `app.live_server` is running and press `Ctrl+C`.
2.  **Stop the Specialist Agent:**
    *   If you are finished testing, go to the terminal where `specialist_agents.stock_info_agent` is running and press `Ctrl+C`. This will also stop the `StockToolServer` subprocess it was managing.
3.  **Stop the MCP Inspector (if running):**
    *   If you still have `mcp dev` (from Section 1) running in a terminal, press `Ctrl+C` there as well.

Congratulations! If you've reached this point and successfully performed an end-to-end test, you have the core Project Horizon system up and running. 


================================================
FILE: LICENSE
================================================
                                 Apache License
                           Version 2.0, January 2004
                        http://www.apache.org/licenses/

   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION

   1. Definitions.

      "License" shall mean the terms and conditions for use, reproduction,
      and distribution as defined by Sections 1 through 9 of this document.

      "Licensor" shall mean the copyright owner or entity authorized by
      the copyright owner that is granting the License.

      "Legal Entity" shall mean the union of the acting entity and all
      other entities that control, are controlled by, or are under common
      control with that entity. For the purposes of this definition,
      "control" means (i) the power, direct or indirect, to cause the
      direction or management of such entity, whether by contract or
      otherwise, or (ii) ownership of fifty percent (50%) or more of the
      outstanding shares, or (iii) beneficial ownership of such entity.

      "You" (or "Your") shall mean an individual or Legal Entity
      exercising permissions granted by this License.

      "Source" form shall mean the preferred form for making modifications,
      including but not limited to software source code, documentation
      source, and configuration files.

      "Object" form shall mean any form resulting from mechanical
      transformation or translation of a Source form, including but
      not limited to compiled object code, generated documentation,
      and conversions to other media types.

      "Work" shall mean the work of authorship, whether in Source or
      Object form, made available under the License, as indicated by a
      copyright notice that is included in or attached to the work
      (an example is provided in the Appendix below).

      "Derivative Works" shall mean any work, whether in Source or Object
      form, that is based on (or derived from) the Work and for which the
      editorial revisions, annotations, elaborations, or other modifications
      represent, as a whole, an original work of authorship. For the purposes
      of this License, Derivative Works shall not include works that remain
      separable from, or merely link (or bind by name) to the interfaces of,
      the Work and Derivative Works thereof.

      "Contribution" shall mean any work of authorship, including
      the original version of the Work and any modifications or additions
      to that Work or Derivative Works thereof, that is intentionally
      submitted to Licensor for inclusion in the Work by the copyright owner
      or by an individual or Legal Entity authorized to submit on behalf of
      the copyright owner. For the purposes of this definition, "submitted"
      means any form of electronic, verbal, or written communication sent
      to the Licensor or its representatives, including but not limited to
      communication on electronic mailing lists, source code control systems,
      and issue tracking systems that are managed by, or on behalf of, the
      Licensor for the purpose of discussing and improving the Work, but
      excluding communication that is conspicuously marked or otherwise
      designated in writing by the copyright owner as "Not a Contribution."

      "Contributor" shall mean Licensor and any individual or Legal Entity
      on behalf of whom a Contribution has been received by Licensor and
      subsequently incorporated within the Work.

   2. Grant of Copyright License. Subject to the terms and conditions of
      this License, each Contributor hereby grants to You a perpetual,
      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
      copyright license to reproduce, prepare Derivative Works of,
      publicly display, publicly perform, sublicense, and distribute the
      Work and such Derivative Works in Source or Object form.

   3. Grant of Patent License. Subject to the terms and conditions of
      this License, each Contributor hereby grants to You a perpetual,
      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
      (except as stated in this section) patent license to make, have made,
      use, offer to sell, sell, import, and otherwise transfer the Work,
      where such license applies only to those patent claims licensable
      by such Contributor that are necessarily infringed by their
      Contribution(s) alone or by combination of their Contribution(s)
      with the Work to which such Contribution(s) was submitted. If You
      institute patent litigation against any entity (including a
      cross-claim or counterclaim in a lawsuit) alleging that the Work
      or a Contribution incorporated within the Work constitutes direct
      or contributory patent infringement, then any patent licenses
      granted to You under this License for that Work shall terminate
      as of the date such litigation is filed.

   4. Redistribution. You may reproduce and distribute copies of the
      Work or Derivative Works thereof in any medium, with or without
      modifications, and in Source or Object form, provided that You
      meet the following conditions:

      (a) You must give any other recipients of the Work or
          Derivative Works a copy of this License; and

      (b) You must cause any modified files to carry prominent notices
          stating that You changed the files; and

      (c) You must retain, in the Source form of any Derivative Works
          that You distribute, all copyright, patent, trademark, and
          attribution notices from the Source form of the Work,
          excluding those notices that do not pertain to any part of
          the Derivative Works; and

      (d) If the Work includes a "NOTICE" text file as part of its
          distribution, then any Derivative Works that You distribute must
          include a readable copy of the attribution notices contained
          within such NOTICE file, excluding those notices that do not
          pertain to any part of the Derivative Works, in at least one
          of the following places: within a NOTICE text file distributed
          as part of the Derivative Works; within the Source form or
          documentation, if provided along with the Derivative Works; or,
          within a display generated by the Derivative Works, if and
          wherever such third-party notices normally appear. The contents
          of the NOTICE file are for informational purposes only and
          do not modify the License. You may add Your own attribution
          notices within Derivative Works that You distribute, alongside
          or as an addendum to the NOTICE text from the Work, provided
          that such additional attribution notices cannot be construed
          as modifying the License.

      You may add Your own copyright statement to Your modifications and
      may provide additional or different license terms and conditions
      for use, reproduction, or distribution of Your modifications, or
      for any such Derivative Works as a whole, provided Your use,
      reproduction, and distribution of the Work otherwise complies with
      the conditions stated in this License.

   5. Submission of Contributions. Unless You explicitly state otherwise,
      any Contribution intentionally submitted for inclusion in the Work
      by You to the Licensor shall be under the terms and conditions of
      this License, without any additional terms or conditions.
      Notwithstanding the above, nothing herein shall supersede or modify
      the terms of any separate license agreement you may have executed
      with Licensor regarding such Contributions.

   6. Trademarks. This License does not grant permission to use the trade
      names, trademarks, service marks, or product names of the Licensor,
      except as required for reasonable and customary use in describing the
      origin of the Work and reproducing the content of the NOTICE file.

   7. Disclaimer of Warranty. Unless required by applicable law or
      agreed to in writing, Licensor provides the Work (and each
      Contributor provides its Contributions) on an "AS IS" BASIS,
      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
      implied, including, without limitation, any warranties or conditions
      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
      PARTICULAR PURPOSE. You are solely responsible for determining the
      appropriateness of using or redistributing the Work and assume any
      risks associated with Your exercise of permissions under this License.

   8. Limitation of Liability. In no event and under no legal theory,
      whether in tort (including negligence), contract, or otherwise,
      unless required by applicable law (such as deliberate and grossly
      negligent acts) or agreed to in writing, shall any Contributor be
      liable to You for damages, including any direct, indirect, special,
      incidental, or consequential damages of any character arising as a
      result of this License or out of the use or inability to use the
      Work (including but not limited to damages for loss of goodwill,
      work stoppage, computer failure or malfunction, or any and all
      other commercial damages or losses), even if such Contributor
      has been advised of the possibility of such damages.

   9. Accepting Warranty or Additional Liability. While redistributing
      the Work or Derivative Works thereof, You may choose to offer,
      and charge a fee for, acceptance of support, warranty, indemnity,
      or other liability obligations and/or rights consistent with this
      License. However, in accepting such obligations, You may act only
      on Your own behalf and on Your sole responsibility, not on behalf
      of any other Contributor, and only if You agree to indemnify,
      defend, and hold each Contributor harmless for any liability
      incurred by, or claims asserted against, such Contributor by reason
      of your accepting any such warranty or additional liability.

   END OF TERMS AND CONDITIONS

   APPENDIX: How to apply the Apache License to your work.

      To apply the Apache License to your work, attach the following
      boilerplate notice, with the fields enclosed by brackets "[]"
      replaced with your own identifying information. (Don't include
      the brackets!)  The text should be enclosed in the appropriate
      comment syntax for the file format. We also recommend that a
      file or class name and description of purpose be included on the
      same "printed page" as the copyright notice for easier
      identification within third-party archives.

   Copyright [yyyy] [name of copyright owner]

   Licensed under the Apache License, Version 2.0 (the "License");
   you may not use this file except in compliance with the License.
   You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.



================================================
FILE: requirements.txt
================================================
# Google Libraries
google-adk==0.3.0
google-genai==1.12.1

# Core application & web serving
python-dotenv==1.1.0
fastapi==0.115.12
uvicorn[standard]==0.34.2 # Includes websockets, http-tools
starlette==0.46.2
sse-starlette==2.3.3
httpx==0.28.1
httpx-sse==0.4.0
pydantic==2.11.3

# MCP & Tools
mcp[cli] @ git+https://github.com/modelcontextprotocol/python-sdk.git@b4c7db6a50a5c88bae1db5c1f7fba44d16eebc6e
finnhub-python==2.4.23

# Testing
pytest==8.3.5
pytest-asyncio==0.26.0


================================================
FILE: .env.example
================================================
# --- Google AI/Vertex AI Configuration ---
# Choose ONE block (Google AI Studio or Vertex AI)

# Option 1: Google AI Studio (Gemini API Key)
GOOGLE_API_KEY="YOUR_GOOGLE_API_KEY_HERE"
GOOGLE_GENAI_USE_VERTEXAI="False"

# Option 2: Vertex AI (using Application Default Credentials)
# GOOGLE_GENAI_USE_VERTEXAI="True"
# GOOGLE_CLOUD_PROJECT="your-gcp-project-id"
# GOOGLE_CLOUD_LOCATION="your-gcp-region"

# --- Service URLs ---
# The URL where the Specialist Agent's A2A server will run
STOCK_INFO_AGENT_A2A_SERVER_HOST=127.0.0.1
STOCK_INFO_AGENT_A2A_SERVER_PORT=8001
STOCK_INFO_AGENT_MODEL="gemini-2.0-flash-001"
MOCK_STOCK_API=False
FINNHUB_API_KEY=<YOUR_FINNHUB_API_KEY>


# --- MCP Server Configuration ---
STOCK_MCP_SERVER_PATH="mcp_servers/stock_mcp_server/server.py" # Relative path from specialist agent perspective

# --- ADK Live Server Configuration ---
# Host and port for the main ADK Live Server (FastAPI/WebSocket server that serves the UI).
LIVE_SERVER_HOST=127.0.0.1
LIVE_SERVER_PORT=8000 # MANDATORY: Port for the ADK Live Server (e.g., 8000). The UI will connect here.
LIVE_SERVER_MODEL="gemini-2.0-flash-live-001"

# Base URL for the StockInfoAgent (A2A Server). The Host Agent will append /.well-known/agent.json to this.
# If you have multiple, comma-separate them: "http://localhost:8001,http://localhost:8002"
SPECIALIST_AGENT_BASE_URLS="http://localhost:8001" # Points to StockInfoAgent A2A server

# Optional: Logging Level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
LOG_LEVEL="INFO"


================================================
FILE: app/live_server.py
================================================
# app/live_server.py
import asyncio
import json
import logging
import os
import uuid
import base64 # Needed for decoding/encoding audio
from pathlib import Path
import sys # To modify path for imports if needed
from contextlib import suppress # For ignoring CancelledError during cleanup

from fastapi import FastAPI, WebSocket, WebSocketDisconnect
from fastapi.staticfiles import StaticFiles
from starlette.responses import FileResponse # Use Starlette directly for FileResponse

# --- ADK Imports ---
from google.adk.runners import Runner
from google.adk.agents.run_config import RunConfig
from google.adk.sessions import InMemorySessionService, Session # Using in-memory for simplicity
from google.adk.agents.live_request_queue import LiveRequestQueue
from google.adk.events import Event, EventActions # Import EventActions for state delta
# Use alias for genai types to avoid conflicts if any
from google.genai import types as genai_types

from typing import Any, Dict, Optional


# --- Configuration ---
from dotenv import load_dotenv
# Load .env file from the parent directory (project root)
dotenv_path = os.path.join(os.path.dirname(__file__), '..', '.env')
load_dotenv(dotenv_path=dotenv_path, override=True)

# Setup logging
logging.basicConfig(level=os.getenv('LOG_LEVEL', 'INFO').upper(),
                   format='%(asctime)s - %(name)s - %(levelname)s - LIVE_SERVER - %(message)s')
logger = logging.getLogger(__name__)

# --- Import the Host Agent CREATION FUNCTION ---
try:
    project_root = Path(__file__).parent.parent
    if str(project_root) not in sys.path:
        sys.path.insert(0, str(project_root))
    from host_agent.agent import create_host_agent
    logger.info("Successfully imported host_agent creation function.")
except ImportError as e:
     logger.critical(f"Could not import host_agent.agent: {e}. Check sys.path and ensure host_agent/agent.py exists.", exc_info=True)
     create_host_agent = None # type: ignore

if not create_host_agent:
    logger.critical("Host agent creation function failed to load. Exiting.")
    sys.exit(1)

APP_NAME = "ProjectHorizonLive"
STATIC_DIR = Path(__file__).parent / "static"

# --- ADK Setup ---
session_service = InMemorySessionService()
runner: Optional[Runner] = None # Initialize as None

# --- FastAPI App ---
app = FastAPI(title="Project Horizon Live Server") # Create app instance early

async def initialize_adk_system():
    """Initializes the ADK system, including specialist agent discovery and HostAgent creation."""
    global runner

    if not create_host_agent:
        logger.critical("create_host_agent function not available. Cannot initialize ADK system.")
        # This should ideally prevent server from starting, but with FastAPI events,
        # we'll log critical and the app might fail to handle requests properly.
        return

    temp_host_agent = await create_host_agent()
    if not temp_host_agent:
        logger.critical("Failed to create HostAgent after discovery.")
        return
    
    runner = Runner(
        app_name=APP_NAME,
        agent=temp_host_agent,
        session_service=session_service,
    )
    logger.info(f"ADK Runner initialized with dynamically configured agent: {temp_host_agent.name}")

# --- FastAPI Startup Event ---
@app.on_event("startup")
async def startup_event():
    logger.info("FastAPI server starting up...")
    await initialize_adk_system()
    if not runner:
        logger.critical("ADK Runner failed to initialize during startup. Server might not function correctly.")
    else:
        logger.info("ADK System initialized successfully within FastAPI startup.")


# --- WebSocket Endpoint ---
@app.websocket("/ws/{session_id}")
async def websocket_endpoint(websocket: WebSocket, session_id: str):
    """Handles WebSocket connection for live agent interaction."""
    await websocket.accept()
    logger.info(f"WebSocket client connected for session: {session_id}")
    user_id = f"live_user_{session_id}"

    live_events: Optional[asyncio.StreamReader] = None
    live_request_queue: Optional[LiveRequestQueue] = None
    adk_run_task: Optional[asyncio.Task] = None
    client_listener_task: Optional[asyncio.Task] = None
    adk_session: Optional[Session] = None

    if not runner:
        logger.error(f"Runner not initialized for session {session_id}. Aborting WebSocket connection.")
        await websocket.close(code=1011, reason="Server not ready (Runner missing)")
        return

    try:
        adk_session = session_service.get_session(
            app_name=APP_NAME, user_id=user_id, session_id=session_id
        )
        if not adk_session:
            adk_session = session_service.create_session(
                app_name=APP_NAME, user_id=user_id, session_id=session_id, state={}
            )
            logger.info(f"Created new ADK session: {session_id}")
        else:
             logger.info(f"Resumed existing ADK session: {session_id}")

        live_request_queue = LiveRequestQueue()
        run_config = RunConfig(response_modalities=["AUDIO"])
        live_events = runner.run_live( # type: ignore
            session=adk_session,
            live_request_queue=live_request_queue,
            run_config=run_config,
        )
        logger.info(f"ADK run_live started for session {session_id}")

        async def adk_to_client():
            nonlocal adk_session
            logger.debug(f"[{session_id}] ADK -> Client task started.")
            audio_chunk_counter = 0
            try:
                async for event in live_events: # type: ignore
                    logger.debug(f"[{session_id}] Raw ADK Event Received: {event}")
                    message_to_send = None
                    event_processed = False

                    if hasattr(event, 'interrupted') and event.interrupted:
                         logger.info(f"[{session_id}] Received interruption signal from ADK.")
                         await websocket.send_json({"type": "interrupted"})
                         logger.info(f"[{session_id}] Sent 'interrupted' signal to client.")

                    if event.content and event.content.parts:
                         part = event.content.parts[0]
                         if part.inline_data and part.inline_data.mime_type.startswith("audio/"):
                              audio_bytes = part.inline_data.data
                              audio_b64 = base64.b64encode(audio_bytes).decode('utf-8')
                              message_to_send = {"type": "audio", "data": audio_b64}
                              audio_chunk_counter += 1
                              if audio_chunk_counter == 1:
                                  logger.info(f"[{session_id}] Receiving audio stream from ADK...")
                              logger.debug(f"[{session_id}] Sending audio chunk #{audio_chunk_counter} ({len(audio_bytes)} bytes) to client.")
                              await websocket.send_json(message_to_send)
                              event_processed = True

                    if event.turn_complete:
                        if audio_chunk_counter > 0:
                            logger.info(f"[{session_id}] Finished sending {audio_chunk_counter} audio chunks.")
                        audio_chunk_counter = 0
                        await websocket.send_json({"type": "turn_complete"})
                        logger.info(f"[{session_id}] Sent turn_complete signal to client.")
                        event_processed = True

                    if not event_processed and not event.actions:
                        is_tool_event = bool(event.get_function_calls() or event.get_function_responses())
                        if not is_tool_event:
                             logger.debug(f"[{session_id}] Skipping event: Author={event.author}, Partial={event.partial}, Content Type={type(event.content.parts[0]).__name__ if event.content and event.content.parts else 'None'}")
                        else:
                             if event.get_function_calls():
                                 logger.debug(f"[{session_id}] Processing event: Tool Call Requested by {event.author}")
                             elif event.get_function_responses():
                                 logger.debug(f"[{session_id}] Processing event: Tool Response from {event.author}")

                    if event.actions and (event.actions.state_delta or event.actions.artifact_delta):
                        logger.debug(f"[{session_id}] Appending event with actions: {event.actions}")
                        if adk_session:
                            session_service.append_event(adk_session, event)
                            adk_session = session_service.get_session(app_name=APP_NAME, user_id=user_id, session_id=session_id) # type: ignore
                            logger.debug(f"[{session_id}] Session state possibly updated by event actions.")
                        else:
                            logger.warning(f"[{session_id}] adk_session is None, cannot append event actions.")
            except WebSocketDisconnect:
                 logger.info(f"[{session_id}] WebSocket disconnected during ADK event processing.")
            except asyncio.CancelledError:
                 logger.info(f"[{session_id}] ADK -> Client task cancelled.")
            except Exception as e:
                 logger.error(f"[{session_id}] Error in ADK -> Client task: {e}", exc_info=True)
            finally:
                 logger.debug(f"[{session_id}] ADK -> Client task finished.")

        async def client_to_adk():
            nonlocal adk_session
            logger.debug(f"[{session_id}] Client -> ADK task started.")
            try:
                while True:
                    data = await websocket.receive_json()
                    message_type = data.get("type")
                    logger.debug(f"[{session_id}] Received '{message_type}' from client.")

                    if message_type == "audio":
                        audio_b64 = data.get("data", "")
                        if audio_b64:
                            audio_bytes = base64.b64decode(audio_b64)
                            if audio_bytes:
                                audio_blob = genai_types.Blob(mime_type='audio/pcm', data=audio_bytes)
                                if live_request_queue: live_request_queue.send_realtime(blob=audio_blob)
                            else:
                                logger.warning(f"[{session_id}] Received empty audio data from client.")
                    elif message_type == "text":
                        text_data = data.get("data", "")
                        if text_data:
                            logger.info(f"[{session_id}] Sending text '{text_data}' to ADK.")
                            content = genai_types.Content(role='user', parts=[genai_types.Part(text=text_data)])
                            if live_request_queue: live_request_queue.send_content(content=content)
                    elif message_type == "end_of_turn":
                        logger.info(f"[{session_id}] Client indicated end of turn.")
                        logger.debug(f"[{session_id}] End of turn signal received, letting Gemini API infer turn end.")
                    elif message_type == "toggle_mock":
                         mock_value = data.get("value", False)
                         logger.info(f"[{session_id}] Setting mock_a2a_calls state to: {mock_value}")
                         state_update_event = Event(
                             author="ui_control",
                             invocation_id = f"ui_mock_toggle_{uuid.uuid4().hex[:8]}",
                             actions=EventActions(
                                 state_delta={'mock_a2a_calls': mock_value}
                             )
                         )
                         if adk_session:
                             session_service.append_event(adk_session, state_update_event)
                             adk_session = session_service.get_session(app_name=APP_NAME, user_id=user_id, session_id=session_id) # type: ignore
                             logger.info(f"[{session_id}] State 'mock_a2a_calls' updated via event to: {adk_session.state.get('mock_a2a_calls')}") # type: ignore
                         else:
                             logger.warning(f"[{session_id}] adk_session is None, cannot update mock_a2a_calls state.")
                    else:
                         logger.warning(f"[{session_id}] Received unknown message type from client: {message_type}")

            except WebSocketDisconnect:
                logger.info(f"[{session_id}] Client WebSocket disconnected (detected in listener).")
                if live_request_queue: live_request_queue.close()
            except asyncio.CancelledError:
                 logger.info(f"[{session_id}] Client -> ADK task cancelled.")
            except Exception as e_inner:
                logger.error(f"[{session_id}] Error in client listener task: {e_inner}", exc_info=True)
                if live_request_queue: live_request_queue.close()
            finally:
                logger.debug(f"[{session_id}] Client -> ADK task finished.")

        logger.info(f"[{session_id}] Starting ADK <-> WebSocket bridge tasks.")
        adk_run_task = asyncio.create_task(adk_to_client())
        client_listener_task = asyncio.create_task(client_to_adk())
        done, pending = await asyncio.wait(
            [adk_run_task, client_listener_task],
            return_when=asyncio.FIRST_COMPLETED,
        )
        logger.info(f"[{session_id}] One of the bridge tasks completed ({len(done)} done, {len(pending)} pending).")

        for task in pending:
            if not task.done():
                logger.debug(f"[{session_id}] Cancelling pending bridge task...")
                task.cancel()
                with suppress(asyncio.CancelledError): await task

    except WebSocketDisconnect:
        logger.info(f"WebSocket client disconnected gracefully for session: {session_id}")
    except asyncio.CancelledError:
         logger.info(f"WebSocket endpoint task cancelled for session: {session_id}")
    except Exception as e_outer:
        logger.error(f"Unhandled error in WebSocket endpoint for session {session_id}: {e_outer}", exc_info=True)
        with suppress(Exception):
            await websocket.close(code=1011, reason=f"Internal Server Error: {type(e_outer).__name__}")
    finally:
        logger.info(f"Performing final cleanup for session: {session_id}")
        if live_request_queue:
             logger.debug(f"[{session_id}] Closing live request queue in final cleanup.")
             try:
                 live_request_queue.close()
             except Exception as q_close_err:
                 logger.warning(f"[{session_id}] Error closing LiveRequestQueue: {q_close_err}")
        if adk_run_task and not adk_run_task.done(): adk_run_task.cancel()
        if client_listener_task and not client_listener_task.done(): client_listener_task.cancel()
        if adk_session:
            try:
                session_service.delete_session(app_name=APP_NAME, user_id=user_id, session_id=session_id)
                logger.info(f"Session removed from service: {session_id}")
            except Exception as del_err:
                 logger.warning(f"[{session_id}] Error deleting session: {del_err}")
        logger.info(f"WebSocket connection fully closed for session: {session_id}")


# --- Static File Serving ---
if not STATIC_DIR.is_dir():
    logger.error(f"Static directory not found at {STATIC_DIR}. UI will not be served.")
else:
    app.mount("/static", StaticFiles(directory=STATIC_DIR), name="static")
    logger.info(f"Serving static files from {STATIC_DIR}")

    @app.get("/")
    async def read_index():
        index_path = STATIC_DIR / "index.html"
        if not index_path.is_file():
            logger.error("index.html not found in static directory.")
            return {"error": "index.html not found"}, 404
        logger.debug("Serving index.html")
        return FileResponse(str(index_path))

# --- Server Startup (for running directly) ---
# The `main_async_startup` is now only needed if you run this file directly.
# Uvicorn will handle app creation and startup events when run as `uvicorn app.live_server:app`
if __name__ == "__main__":
    project_root_path = Path(__file__).parent.parent
    if str(project_root_path) not in sys.path:
        sys.path.insert(0, str(project_root_path))
        logger.debug(f"Added project root to sys.path for direct execution: {project_root_path}")

    LIVE_SERVER_MODEL_ID = os.getenv("LIVE_SERVER_MODEL")
    if not LIVE_SERVER_MODEL_ID:
        logger.warning("LIVE_SERVER_MODEL env var not set. Defaulting to 'gemini-2.0-flash-exp'.")
        LIVE_SERVER_MODEL_ID = "gemini-2.0-flash-exp"

    LIVE_SERVER_HOST = os.getenv("LIVE_SERVER_HOST")
    if LIVE_SERVER_HOST is None:
        logger.critical("CRITICAL: LIVE_SERVER_HOST env var not set.")
        sys.exit(1)

    raw_port = os.getenv("LIVE_SERVER_PORT")
    if raw_port is None:
        logger.critical("LIVE_SERVER_PORT env var not set.")
        sys.exit(1)
    
    try:
        LIVE_SERVER_PORT = int(raw_port)
    except ValueError:
        logger.critical(f"Invalid LIVE_SERVER_PORT: '{raw_port}'. Must be integer.")
        sys.exit(1)

    # When running directly, we need to manually trigger the startup event logic
    # (or Uvicorn does it if 'app' object is passed)
    # Uvicorn will call startup events registered on the app object.
    # No need to call initialize_adk_system() directly here if Uvicorn is used.
    logger.info(f"Starting Project Horizon Live Server (direct run) on http://{LIVE_SERVER_HOST}:{LIVE_SERVER_PORT}")
    try:
        import uvicorn
        uvicorn.run(app, host=LIVE_SERVER_HOST, port=LIVE_SERVER_PORT, log_level="info")
    except ImportError:
         logger.critical("Uvicorn not installed. Run 'pip install uvicorn[standard]'.")
    except Exception as startup_error:
         logger.critical(f"Failed to start Uvicorn server: {startup_error}", exc_info=True)


================================================
FILE: app/static/adk-websocket-api.js
================================================
// app/static/adk-websocket-api.js

// Ensure EventEmitter3 is loaded (e.g., via CDN in index.html)
const EventEmitter = window.EventEmitter3;

// --- Assume these classes are available globally or via imports ---
// --- You MUST copy the corresponding .js files from Pastra   ---
// --- into ./audio/ and ./utils/                           ---
import { AudioRecorder } from './audio/audio-recorder.js';
import { AudioStreamer } from './audio/audio-streamer.js';
import { base64ToArrayBuffer } from './utils/utils.js';
// ---------------------------------------------------------------

class ADKWebSocketAPI extends EventEmitter {
    constructor() {
        super(); // Initialize EventEmitter
        this.ws = null;
        this.audioContext = null; // Keep initialization lazy but ensure resumed
        this.audioRecorder = new AudioRecorder();
        this.audioStreamer = null;
        this.isRecording = false;
        this.isMuted = false; // Start unmuted
        this.isConnected = false;
        this.sessionID = null;
        this.statusIndicator = document.getElementById('statusIndicator');
        this.chatOutput = document.getElementById('chatOutput');
        this.connectButton = document.getElementById('connectButton');
        this.stopButton = document.getElementById('stopButton');
        this.micButton = document.getElementById('micButton');
        this.connectContainer = document.getElementById('connectButtonContainer');
        this.mediaContainer = document.getElementById('mediaButtonsContainer');

        this._bindUIEvents();
        console.log("ADKWebSocketAPI initialized."); // Log constructor finish
    }

    _updateStatusIndicator(status) { // 'offline', 'connecting', 'online', 'error'
        this.statusIndicator.className = `status-indicator ${status}`;
        this.statusIndicator.title = status.charAt(0).toUpperCase() + status.slice(1);
    }

    _logToUI(message, type = 'info') { // type: 'user', 'agent', 'info', 'error'
        const p = document.createElement('p');
        p.textContent = message;
        p.className = `${type}-message`; // Apply class based on type
        this.chatOutput.appendChild(p);
        // Auto-scroll to bottom
        this.chatOutput.scrollTop = this.chatOutput.scrollHeight;
    }

    // *** CHANGE 1: Make initializeAudio async ***
    async initializeAudio() {
        try {
            if (!this.audioContext) {
                console.log("Creating AudioContext...");
                this.audioContext = new (window.AudioContext || window.webkitAudioContext)({
                    sampleRate: 24000 // Matches streamer and likely ADK output
                });
                console.log("AudioContext created, state:", this.audioContext.state);
            }
            // Resume context on user interaction (required by browsers)
            if (this.audioContext.state === 'suspended') {
                console.log("Attempting to resume suspended AudioContext...");
                await this.audioContext.resume();
                console.log("AudioContext resumed, new state:", this.audioContext.state);
            }
            // Add log right before creating streamer
            if (!this.audioStreamer && this.audioContext) {
                 console.log(`Creating AudioStreamer with context state: ${this.audioContext.state}`);
                 this.audioStreamer = new AudioStreamer(this.audioContext);
                 this.audioStreamer.onComplete = () => console.log("AudioStreamer: Playback complete.");
                 console.log("AudioStreamer created.");
            }
            console.log("Audio initialization/resume complete.");
            return true; // Indicate success
        } catch (error) {
             console.error("Failed to initialize audio:", error);
             this._logToUI(`Error initializing audio: ${error.message}`, "error");
             return false; // Indicate failure
        }
    }

    // *** CHANGE 2: Modify connect to call initializeAudio ***
    async connect() { // Make connect async
        this.sessionID = uuid.v4();
        const wsProtocol = window.location.protocol === 'https:' ? 'wss:' : 'ws:';
        // Use the port the current page is served from
        const backendPort = window.location.port || (wsProtocol === "wss:" ? "443" : "80"); 
        const wsEndpoint = `${wsProtocol}//${window.location.hostname}:${backendPort}/ws/${this.sessionID}`;

        console.log('Attempting to connect WebSocket to:', wsEndpoint);
        this._logToUI("Connecting to agent...", "info");
        this._updateStatusIndicator("connecting");

        return new Promise((resolve, reject) => {
            if (this.ws && this.ws.readyState === WebSocket.OPEN) {
                console.warn("WebSocket already open.");
                resolve();
                return;
            }

            try {
                 this.ws = new WebSocket(wsEndpoint);
            } catch (error) {
                 console.error("WebSocket creation failed:", error);
                 this._logToUI(`WebSocket Error: ${error.message}`, "error");
                 this._updateStatusIndicator("error");
                 reject(error);
                 return;
            }


            this.ws.onopen = async () => { // Make onopen async
                console.log('WebSocket connection established.');
                this.isConnected = true;

                console.log("Attempting to initialize audio system on connect...");
                const audioInitialized = await this.initializeAudio();
                console.log(`Audio initialization result: ${audioInitialized}`);
                console.log(`AudioContext state after init: ${this.audioContext?.state}`); // Log state again

                if (audioInitialized) {
                    this._updateStatusIndicator("online"); // Set status *after* successful audio init
                    this._logToUI("Connected! Audio ready. Press Mic to talk.", "info");
                    // Update UI: Hide Connect, Show Controls
                    this.connectContainer.classList.add('hidden');
                    this.mediaContainer.classList.remove('hidden');
                    this.micButton.disabled = false; // Enable mic button
                    resolve(); // Resolve the promise after audio is ready
                } else {
                    this._updateStatusIndicator("error"); // Show error if audio failed
                     this._logToUI("Connected, but failed to initialize audio playback.", "error");
                     // Still show connected, but warn user playback might fail
                     this.connectContainer.classList.add('hidden');
                     this.mediaContainer.classList.remove('hidden');
                     this.micButton.disabled = false; // Mic might still work for input
                     // Reject or resolve based on whether audio playback is critical
                     reject(new Error("Audio initialization failed")); // Reject if audio must work
                }
            };

            this.ws.onmessage = async (event) => { // Keep async
                try {
                    const message = JSON.parse(event.data);
                    console.log(`WebSocket Message Received: Type=${message.type}, ContextState=${this.audioContext?.state}`); // Log type and state

                    if (message.type === 'audio') {
                        const canPlay = !!this.audioStreamer && this.audioContext?.state === 'running';
                        console.log(`Audio message received. Can play? ${canPlay}`); // Log the check result

                        if (canPlay) {
                            const audioBytes = base64ToArrayBuffer(message.data);
                            console.log(`Queuing ${audioBytes.byteLength} audio bytes for playback.`);
                            this.audioStreamer.addPCM16(new Uint8Array(audioBytes));
                        } else {
                             console.warn("Audio streamer not ready or context not running. Cannot play audio chunk.", { streamer: !!this.audioStreamer, contextState: this.audioContext?.state });
                             // Try resuming again *just in case*
                             if(this.audioContext && this.audioContext.state === 'suspended') {
                                 console.log("Attempting to resume suspended context during message handling...");
                                 await this.audioContext.resume();
                                 console.log(`Context state after resume attempt: ${this.audioContext.state}`);
                                 // If resume succeeded, maybe try adding the chunk again? Careful about race conditions.
                                 if (this.audioContext.state === 'running' && this.audioStreamer) {
                                     console.log("Context resumed, retrying addPCM16 for the missed chunk.");
                                     const audioBytes = base64ToArrayBuffer(message.data);
                                     this.audioStreamer.addPCM16(new Uint8Array(audioBytes));
                                 }
                             }
                        }
                    } else if (message.type === 'text') {
                        console.log("Received text message:", message.data);
                        this._logToUI(message.data, "agent");
                    } else if (message.type === 'interrupted') {
                        console.log("Received interruption signal from server.");
                        if (this.audioStreamer) {
                            console.log("Stopping audio streamer due to interruption.");
                            this.audioStreamer.stop();
                        }
                        this._logToUI("Agent response interrupted.", "info");
                    } else if (message.type === 'turn_complete') {
                         console.log("Received turn_complete message.");
                         if (this.audioStreamer) this.audioStreamer.complete();
                    } else if (message.type === 'error') {
                        console.error("Received error message:", message.data);
                        this._logToUI(`Server Error: ${message.data}`, "error");
                    }

                } catch (error) {
                    console.error('Error processing WebSocket message:', error);
                    this._logToUI("Error processing server message.", "error");
                }
            };

            this.ws.onerror = (error) => {
                console.error('WebSocket Error:', error);
                this.isConnected = false;
                this._updateStatusIndicator("error");
                // Try to log the specific event if possible, might give clues
                let errorMsg = "Connection error.";
                // Check if it's a proper ErrorEvent (browser standard)
                if (error instanceof ErrorEvent && error.message) {
                    errorMsg = `Connection error: ${error.message}`;
                } else if (typeof error === 'string') {
                     errorMsg = `Connection error: ${error}`;
                }
                 console.error("Detailed WebSocket error event:", error); // Log the raw event
                this._logToUI(errorMsg, "error");
                this._resetUI();
                reject(error instanceof Error ? error : new Error(errorMsg)); // Reject promise on error
            };


            this.ws.onclose = (event) => {
                console.log('WebSocket connection closed:', event.code, event.reason);
                this.isConnected = false;
                this._updateStatusIndicator("offline");
                this._logToUI("Connection closed.", "info");
                this._resetUI(); // Reset UI on close
                // Optionally trigger automatic reconnection here
                // If the promise hasn't resolved/rejected yet (e.g., closed during initial connection)
                // reject(new Error(`WebSocket closed prematurely: Code ${event.code}`));
            };
        });
    }

    _sendMessage(message) {
        if (this.ws && this.ws.readyState === WebSocket.OPEN) {
            // console.debug("Sending WebSocket Message:", message.type); // Keep logging minimal
            this.ws.send(JSON.stringify(message));
        } else {
            console.error('WebSocket is not open. Cannot send message.');
            this._logToUI("Connection lost.", "error");
            this._resetUI();
        }
    }

    sendAudioChunk(base64Audio) {
        if (!this.isMuted) { // Only send if not muted
             this._sendMessage({ type: 'audio', data: base64Audio });
        }
    }

    sendTextMessage(text) {
        this._logToUI(text, "user"); // Log user text to chat
        this._sendMessage({ type: 'text', data: text });
        this.endUserTurn(); // End turn immediately after sending text
    }

    endUserTurn() {
        console.log("Signaling end of user turn.");
        this._sendMessage({ type: 'end_of_turn' });
    }

    // *** CHANGE 4: Make _startRecording async ***
    async _startRecording() { // Make async
        if (this.isRecording) return;
        try {
            // Ensure audio context is ready before starting recorder
            // Although initializeAudio is called on connect, call it again here
            // to be absolutely sure and handle cases where it might have been suspended.
            const audioReady = await this.initializeAudio();
            if (!audioReady) {
                 throw new Error("Audio context could not be initialized/resumed.");
            }

            await this.audioRecorder.start();
            this.isRecording = true;
            this.isMuted = false; // Start unmuted
            console.log("Audio recording started.");
            this._logToUI("üé§ Recording... (Click Mic again to stop)", "info");
            this.micButton.classList.add('active');
            this.micButton.title = "Stop Recording";
            this.micButton.querySelector('.material-symbols-outlined').textContent = 'stop_circle'; // Change icon

            // Send audio chunks
            this.audioRecorder.on('data', (base64Data) => {
                if (this.isConnected && !this.isMuted) { // Check connection and mute state
                    this.sendAudioChunk(base64Data);
                }
            });
        } catch (error) {
            console.error('Error starting recording:', error);
            this._logToUI(`Error starting microphone: ${error.message}`, "error");
            // Reset button state if recording failed to start
            this.isRecording = false;
            this.micButton.classList.remove('active');
            this.micButton.title = "Start Recording";
            this.micButton.querySelector('.material-symbols-outlined').textContent = 'mic';
        }
    }

    _stopRecording() {
        if (!this.isRecording) return;
        this.audioRecorder.stop();
        this.isRecording = false;
        this.isMuted = false; // Reset mute state
        console.log("Audio recording stopped.");
        this._logToUI("Recording stopped.", "info");
        this.micButton.classList.remove('active');
        this.micButton.classList.remove('muted'); // Ensure mute style is off
        this.micButton.title = "Start Recording";
        this.micButton.querySelector('.material-symbols-outlined').textContent = 'mic'; // Reset icon
        this.endUserTurn(); // Signal end of input turn
        if (this.audioStreamer) this.audioStreamer.stop(); // Stop playback if any was happening
    }

    // No toggleMute needed for simplified UI, just start/stop

    disconnect() {
        if (this.ws) {
            console.log("Disconnecting WebSocket.");
            this._stopRecording(); // Ensure recording stops if active
            if (this.audioStreamer) this.audioStreamer.stop();
            this.ws.close(); // Triggers onclose handler
        }
        this._resetUI(); // Update UI immediately
    }

    _resetUI() {
        this.isConnected = false;
        this.isRecording = false;
        this.isMuted = false;
        this.connectContainer.classList.remove('hidden');
        this.mediaContainer.classList.add('hidden');
        this.micButton.disabled = true;
        this.micButton.classList.remove('active', 'muted');
        this.micButton.querySelector('.material-symbols-outlined').textContent = 'mic';
        this.micButton.title = "Start/Stop Recording";
         // Don't clear chat on disconnect/error, maybe add separator?
        // this.chatOutput.innerHTML = '<p class="info-message">Disconnected. Click Connect to restart.</p>';
    }

    // *** CHANGE 5: Make button handler async ***
    _bindUIEvents() {
        this.connectButton.onclick = async () => { // Make async
            this.connectButton.disabled = true;
            this._logToUI("Connecting...", "info");
            try {
                await this.connect(); // Await the connect promise
                 // Success is handled within connect's onopen
            } catch (error) {
                // Error handling moved inside connect's onerror/onclose/reject
                 console.error("Connect button click failed:", error);
                 // LogUI and status indicator are handled by connect error paths
                this.connectButton.disabled = false; // Re-enable on failure
                 this._updateStatusIndicator("error"); // Ensure error state shown
                 // Optional: Log a more specific message if connect rejected
                 this._logToUI(`Connection Failed: ${error.message || 'Unknown error'}`, "error");
            }
        };

        this.stopButton.onclick = () => {
            this.disconnect();
        };

        this.micButton.onclick = async () => { // Make async because _startRecording is async
            if (!this.isConnected) return;
            if (this.isRecording) {
                this._stopRecording();
            } else {
                await this._startRecording(); // Await start recording
            }
        };
    }
}

// Initialize the API and make it globally accessible (or use modules)
window.adkApi = new ADKWebSocketAPI();
console.log("adkApi created."); // Log instance creation


================================================
FILE: app/static/index.html
================================================
<!DOCTYPE html>
<html>
<head>
  <title>Project Horizon - Live Agent</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, viewport-fit=cover">
  <meta name="theme-color" content="#1a1a1a">
  <link rel="stylesheet" href="/static/styles.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@20..48,100..700,0..1,-50..200" />
  <!-- <link rel="icon" type="image/x-icon" href="/static/favicon.ico"> -->

  <!-- *** ADD THIS SCRIPT TAG FOR UUID LIBRARY *** -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/uuid/8.3.2/uuid.min.js" integrity="sha512-UNM1njAgOFUa74Z0bADwAq8gbTcqZC8Ej4xPSzpnh0l6KMevwvkBvbldF9uR++qKeJ+MOZHRjV1HZjoRvjDfNQ==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
  <!-- ****************************************** -->

</head>
<body>
  <div class="header-section">
    <h1>Project Horizon</h1>
    <span id="statusIndicator" class="status-indicator offline" title="Disconnected"></span>
  </div>

  <div id="chatOutput" class="chat-output">
     <p class="info-message">Click Connect (‚ñ∂) to start the agent session.</p>
  </div>

  <div class="controls">
    <div id="connectButtonContainer" class="centered-button-container">
      <button id="connectButton" class="action-button connect-button" title="Connect to Agent">
        <span class="material-symbols-outlined">play_arrow</span>
      </button>
    </div>
    <div id="mediaButtonsContainer" class="media-buttons-container hidden">
      <button id="stopButton" class="action-button stop-button" title="Disconnect Session">
        <span class="material-symbols-outlined">stop</span>
      </button>
      <button id="micButton" class="action-button mic-button" disabled title="Start/Stop Recording">
        <span class="material-symbols-outlined">mic</span>
      </button>
    </div>
  </div>

  <!-- Load JS Libraries -->
  <script src="https://cdn.jsdelivr.net/npm/eventemitter3@5.0.1/dist/eventemitter3.umd.min.js"></script>
  <!-- Your main application logic (ensure UUID script is loaded before this) -->
  <script type="module" src="/static/adk-websocket-api.js"></script>
</body>
</html>


================================================
FILE: app/static/styles.css
================================================
/* app/static/styles.css - Simplified Styles */
* {
    margin: 0;
    padding: 0;
    box-sizing: border-box;
}

body {
    font-family: system-ui, -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Open Sans', 'Helvetica Neue', sans-serif;
    display: flex;
    flex-direction: column;
    height: 100vh; /* Full viewport height */
    background-color: #1e1e1e; /* Dark background */
    color: #e0e0e0; /* Light text */
    overflow: hidden; /* Prevent body scroll */
}

.header-section {
    background-color: #333;
    color: white;
    padding: 10px 20px;
    display: flex;
    justify-content: space-between;
    align-items: center;
    border-bottom: 1px solid #444;
    flex-shrink: 0; /* Prevent header from shrinking */
}

.header-section h1 {
    margin: 0;
    font-size: 1.4em;
    font-weight: 500;
}

.status-indicator {
    display: inline-block;
    width: 12px;
    height: 12px;
    border-radius: 50%;
    background-color: #dc3545; /* Offline: Red */
    margin-left: 10px;
    transition: background-color 0.3s ease;
}
.status-indicator.online { background-color: #28a745; } /* Online: Green */
.status-indicator.error { background-color: #ffc107; } /* Error: Yellow/Orange */

.chat-output {
    flex-grow: 1; /* Takes up remaining vertical space */
    overflow-y: auto; /* Enable scrolling for chat messages */
    padding: 15px;
    background-color: #2a2a2a; /* Slightly lighter dark */
    display: flex;
    flex-direction: column;
}

.chat-output p {
    margin-bottom: 10px;
    padding: 10px 15px;
    border-radius: 18px;
    max-width: 75%;
    word-wrap: break-word;
    line-height: 1.4;
}

.user-message {
    background-color: #007bff; /* Blue for user */
    color: white;
    align-self: flex-end;
    margin-left: 25%;
}

.agent-message {
    background-color: #444; /* Dark grey for agent */
    color: #e0e0e0;
    align-self: flex-start;
    margin-right: 25%;
}
.info-message {
    font-style: italic;
    color: #aaa;
    text-align: center;
    background-color: transparent;
    align-self: center;
}
.error-message {
    color: #ff8a80; /* Light red for errors */
    font-weight: bold;
    text-align: center;
    background-color: rgba(255, 0, 0, 0.1);
    border: 1px solid #f44336;
    align-self: center;
    max-width: 90%;
}

.controls {
    padding: 15px;
    background-color: #333;
    border-top: 1px solid #444;
    flex-shrink: 0; /* Prevent controls from shrinking */
}

.centered-button-container, .media-buttons-container {
    display: flex;
    justify-content: center;
    align-items: center;
    gap: 20px; /* Spacing between buttons */
    height: 70px; /* Fixed height for control area */
}

.action-button {
    width: 56px;
    height: 56px;
    border-radius: 50%;
    border: none;
    background-color: #555; /* Neutral dark grey */
    color: #e0e0e0;
    cursor: pointer;
    display: flex;
    align-items: center;
    justify-content: center;
    transition: background-color 0.2s ease, transform 0.1s ease;
}
.action-button:disabled {
    background-color: #444;
    color: #777;
    cursor: not-allowed;
}
.action-button:not(:disabled):hover {
    background-color: #666;
}
.action-button:not(:disabled):active {
    transform: scale(0.92);
    background-color: #777;
}

/* Specific Button Styles */
.connect-button { background-color: #28a745; color: white; } /* Green for connect */
.connect-button:not(:disabled):hover { background-color: #218838; }
.stop-button { background-color: #dc3545; color: white; } /* Red for stop */
.stop-button:not(:disabled):hover { background-color: #c82333; }
.mic-button.active { background-color: #dc3545; color: white; } /* Red when recording */
.mic-button.muted { background-color: #6c757d; } /* Grey when muted */

.hidden { display: none !important; } /* Utility to hide elements */

/* Mock Toggle Styles */
.mock-toggle-container {
    display: flex;
    align-items: center;
    gap: 8px;
    color: #ccc; /* Lighter text for toggle */
    background-color: rgba(255, 255, 255, 0.1); /* Slight background */
    padding: 5px 10px;
    border-radius: 15px;
    cursor: pointer; /* Make the whole area clickable */
}
.mock-toggle-container input[type="checkbox"] {
    cursor: pointer;
}
.mock-toggle-container label {
    cursor: pointer;
    user-select: none; /* Prevent text selection on label click */
}

/* Material Symbols */
.material-symbols-outlined {
  font-variation-settings:
  'FILL' 0,
  'wght' 400,
  'GRAD' 0,
  'opsz' 24
}

/* Responsive Adjustments (Optional) */
@media (max-width: 600px) {
    .header-section h1 { font-size: 1.2em; }
    .chat-output p { max-width: 90%; font-size: 0.95em; }
    .action-button { width: 50px; height: 50px; }
    .media-buttons-container { gap: 15px; }
    .mock-toggle-container label { font-size: 0.9em; }
}


================================================
FILE: app/static/audio/audio-recorder.js
================================================
/**
 * Copyright 2025 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

import { audioContext } from "../utils/utils.js";
import { createWorkletFromSrc, registeredWorklets } from "./audioworklet-registry.js";
import AudioRecordingWorklet from "./audio-recording-worklet.js";

function arrayBufferToBase64(buffer) {
  var binary = "";
  var bytes = new Uint8Array(buffer);
  var len = bytes.byteLength;
  for (var i = 0; i < len; i++) {
    binary += String.fromCharCode(bytes[i]);
  }
  return window.btoa(binary);
}

export class AudioRecorder extends EventEmitter3 {
  constructor() {
    super();
    this.sampleRate = 16000;
    this.stream = undefined;
    this.audioContext = undefined;
    this.source = undefined;
    this.recording = false;
    this.recordingWorklet = undefined;
    this.starting = null;
    this.isMuted = false;
  }

  async start() {
    if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
      throw new Error("Could not request user media");
    }

    this.starting = new Promise(async (resolve, reject) => {
      this.stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      this.audioContext = await audioContext({ sampleRate: this.sampleRate });
      this.source = this.audioContext.createMediaStreamSource(this.stream);

      const workletName = "audio-recorder-worklet";
      const workletSrc = AudioRecordingWorklet;

      if (!registeredWorklets.has(this.audioContext)) {
        registeredWorklets.set(this.audioContext, {});
      }

      const registry = registeredWorklets.get(this.audioContext);
      if (!registry[workletName]) {
        const src = createWorkletFromSrc(workletName, workletSrc);
        await this.audioContext.audioWorklet.addModule(src);
        registry[workletName] = {
          node: new AudioWorkletNode(this.audioContext, workletName),
          handlers: []
        };
      }

      this.recordingWorklet = registry[workletName].node;

      this.recordingWorklet.port.onmessage = async (ev) => {
        const arrayBuffer = ev.data.data.int16arrayBuffer;

        if (arrayBuffer) {
          const arrayBufferString = arrayBufferToBase64(arrayBuffer);
          this.emit("data", arrayBufferString);
        }
      };
      this.source.connect(this.recordingWorklet);

      this.recording = true;
      resolve();
      this.starting = null;
    });
  }

  stop() {
    const handleStop = () => {
      this.source?.disconnect();
      this.stream?.getTracks().forEach((track) => track.stop());
      this.stream = undefined;
      this.recordingWorklet = undefined;
    };
    if (this.starting) {
      this.starting.then(handleStop);
      return;
    }
    handleStop();
  }

  mute() {
    if (this.source && this.recordingWorklet && !this.isMuted) {
      this.source.disconnect(this.recordingWorklet);
      this.isMuted = true;
    }
  }

  unmute() {
    if (this.source && this.recordingWorklet && this.isMuted) {
      this.source.connect(this.recordingWorklet);
      this.isMuted = false;
    }
  }
}


================================================
FILE: app/static/audio/audio-recording-worklet.js
================================================
/**
 * Copyright 2025 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

const workletCode = `
class AudioProcessingWorklet extends AudioWorkletProcessor {
  // send and clear buffer every 2048 samples, 
  // which at 16khz is about 8 times a second
  buffer = new Int16Array(2048);

  // current write index
  bufferWriteIndex = 0;

  constructor() {
    super();
  }

  process(inputs) {
    if (inputs[0].length) {
      const channel0 = inputs[0][0];
      this.processChunk(channel0);
    }
    return true;
  }

  sendAndClearBuffer() {
    this.port.postMessage({
      event: "chunk",
      data: {
        int16arrayBuffer: this.buffer.slice(0, this.bufferWriteIndex).buffer,
      },
    });
    this.bufferWriteIndex = 0;
  }

  processChunk(float32Array) {
    const l = float32Array.length;
    
    for (let i = 0; i < l; i++) {
      // convert float32 -1 to 1 to int16 -32768 to 32767
      const int16Value = float32Array[i] * 32768;
      this.buffer[this.bufferWriteIndex++] = int16Value;
      if(this.bufferWriteIndex >= this.buffer.length) {
        this.sendAndClearBuffer();
      }
    }

    if(this.bufferWriteIndex >= this.buffer.length) {
      this.sendAndClearBuffer();
    }
  }
}

registerProcessor('audio-recorder-worklet', AudioProcessingWorklet);
`;

export default workletCode;


================================================
FILE: app/static/audio/audio-streamer.js
================================================
/**
 * Copyright 2025 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

export class AudioStreamer {
    constructor(audioContext) {
      this.context = audioContext;
      this.sampleRate = 24000; // Output sample rate as per API spec
      this.audioQueue = [];
      this.isPlaying = false;
      this.currentSource = null;
      this.gainNode = this.context.createGain();
      this.gainNode.connect(this.context.destination);
      this.addPCM16 = this.addPCM16.bind(this);
      this.onComplete = () => {};
      this.playbackTimeout = null;
      this.lastPlaybackTime = 0;
    }

    addPCM16(chunk) {
      // Convert incoming PCM16 data to float32
      const float32Array = new Float32Array(chunk.length / 2);
      const dataView = new DataView(chunk.buffer);

      for (let i = 0; i < chunk.length / 2; i++) {
        try {
          const int16 = dataView.getInt16(i * 2, true);
          float32Array[i] = int16 / 32768;
        } catch (e) {
          console.error(e);
        }
      }

      // Create and fill audio buffer
      const audioBuffer = this.context.createBuffer(1, float32Array.length, this.sampleRate);
      audioBuffer.getChannelData(0).set(float32Array);

      // Add to queue and start playing if needed
      this.audioQueue.push(audioBuffer);
      
      if (!this.isPlaying) {
        this.isPlaying = true;
        this.lastPlaybackTime = this.context.currentTime;
        this.playNextBuffer();
      }

      // Ensure playback continues if it was interrupted
      this.checkPlaybackStatus();
    }

    checkPlaybackStatus() {
      // Clear any existing timeout
      if (this.playbackTimeout) {
        clearTimeout(this.playbackTimeout);
      }

      // Set a new timeout to check playback status
      this.playbackTimeout = setTimeout(() => {
        const now = this.context.currentTime;
        const timeSinceLastPlayback = now - this.lastPlaybackTime;

        // If more than 1 second has passed since last playback and we have buffers to play
        if (timeSinceLastPlayback > 1 && this.audioQueue.length > 0 && this.isPlaying) {
          console.log('Playback appears to have stalled, restarting...');
          this.playNextBuffer();
        }

        // Continue checking if we're still playing
        if (this.isPlaying) {
          this.checkPlaybackStatus();
        }
      }, 1000);
    }

    playNextBuffer() {
      if (this.audioQueue.length === 0) {
        this.isPlaying = false;
        return;
      }

      // Update last playback time
      this.lastPlaybackTime = this.context.currentTime;

      try {
        const audioBuffer = this.audioQueue.shift();
        const source = this.context.createBufferSource();
        source.buffer = audioBuffer;
        source.connect(this.gainNode);

        // Store current source for potential stopping
        if (this.currentSource) {
          try {
            this.currentSource.disconnect();
          } catch (e) {
            // Ignore disconnection errors
          }
        }
        this.currentSource = source;

        // When this buffer ends, play the next one
        source.onended = () => {
          this.lastPlaybackTime = this.context.currentTime;
          if (this.audioQueue.length > 0) {
            // Small delay to ensure smooth transition
            setTimeout(() => this.playNextBuffer(), 0);
          } else {
            this.isPlaying = false;
            this.onComplete();
          }
        };

        // Start playing immediately
        source.start(0);
      } catch (error) {
        console.error('Error during playback:', error);
        // Try to recover by playing next buffer
        if (this.audioQueue.length > 0) {
          setTimeout(() => this.playNextBuffer(), 100);
        } else {
          this.isPlaying = false;
        }
      }
    }

    stop() {
      this.isPlaying = false;
      if (this.playbackTimeout) {
        clearTimeout(this.playbackTimeout);
        this.playbackTimeout = null;
      }
      if (this.currentSource) {
        try {
          this.currentSource.stop();
          this.currentSource.disconnect();
        } catch (e) {
          // Ignore if already stopped
        }
      }
      this.audioQueue = [];
      this.gainNode.gain.linearRampToValueAtTime(0, this.context.currentTime + 0.1);

      setTimeout(() => {
        this.gainNode.disconnect();
        this.gainNode = this.context.createGain();
        this.gainNode.connect(this.context.destination);
      }, 200);
    }

    async resume() {
      if (this.context.state === 'suspended') {
        await this.context.resume();
      }
      this.lastPlaybackTime = this.context.currentTime;
      this.gainNode.gain.setValueAtTime(1, this.context.currentTime);
      if (this.audioQueue.length > 0 && !this.isPlaying) {
        this.isPlaying = true;
        this.playNextBuffer();
      }
    }

    complete() {
      if (this.audioQueue.length > 0) {
        // Let the remaining buffers play out
        return;
      }
      if (this.playbackTimeout) {
        clearTimeout(this.playbackTimeout);
        this.playbackTimeout = null;
      }
      this.onComplete();
    }
  }


================================================
FILE: app/static/audio/audioworklet-registry.js
================================================
/**
 * Copyright 2025 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

/**
 * A registry to map attached worklets by their audio-context
 * any module using `audioContext.audioWorklet.addModule(` should register the worklet here
 */
export const registeredWorklets = new Map();

export function createWorkletFromSrc(name, workletSrc) {
  const blob = new Blob(
    [`${workletSrc}`],
    { type: 'application/javascript' }
  );
  return URL.createObjectURL(blob);
}


================================================
FILE: app/static/utils/utils.js
================================================
/**
 * Copyright 2025 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

export async function audioContext({ sampleRate }) {
  const context = new (window.AudioContext || window.webkitAudioContext)({ sampleRate });
  await context.resume();
  return context;
}

/**
 * Convert a base64 string to an ArrayBuffer
 * @param {string} base64 The base64 string to convert
 * @returns {ArrayBuffer} The converted ArrayBuffer
 */
export function base64ToArrayBuffer(base64) {
  const binaryString = atob(base64);
  const bytes = new Uint8Array(binaryString.length);
  for (let i = 0; i < binaryString.length; i++) {
    bytes[i] = binaryString.charCodeAt(i);
  }
  return bytes.buffer;
}



================================================
FILE: common/__init__.py
================================================



================================================
FILE: common/types.py
================================================
from typing import Union, Any
from pydantic import BaseModel, Field, TypeAdapter
from typing import Literal, List, Annotated, Optional
from datetime import datetime
from pydantic import model_validator, ConfigDict, field_serializer
from uuid import uuid4
from enum import Enum
from typing_extensions import Self


class TaskState(str, Enum):
    SUBMITTED = "submitted"
    WORKING = "working"
    INPUT_REQUIRED = "input-required"
    COMPLETED = "completed"
    CANCELED = "canceled"
    FAILED = "failed"
    UNKNOWN = "unknown"


class TextPart(BaseModel):
    type: Literal["text"] = "text"
    text: str
    metadata: dict[str, Any] | None = None


class FileContent(BaseModel):
    name: str | None = None
    mimeType: str | None = None
    bytes: str | None = None
    uri: str | None = None

    @model_validator(mode="after")
    def check_content(self) -> Self:
        if not (self.bytes or self.uri):
            raise ValueError("Either 'bytes' or 'uri' must be present in the file data")
        if self.bytes and self.uri:
            raise ValueError(
                "Only one of 'bytes' or 'uri' can be present in the file data"
            )
        return self


class FilePart(BaseModel):
    type: Literal["file"] = "file"
    file: FileContent
    metadata: dict[str, Any] | None = None


class DataPart(BaseModel):
    type: Literal["data"] = "data"
    data: dict[str, Any]
    metadata: dict[str, Any] | None = None


Part = Annotated[Union[TextPart, FilePart, DataPart], Field(discriminator="type")]


class Message(BaseModel):
    role: Literal["user", "agent"]
    parts: List[Part]
    metadata: dict[str, Any] | None = None


class TaskStatus(BaseModel):
    state: TaskState
    message: Message | None = None
    timestamp: datetime = Field(default_factory=datetime.now)

    @field_serializer("timestamp")
    def serialize_dt(self, dt: datetime, _info):
        return dt.isoformat()


class Artifact(BaseModel):
    name: str | None = None
    description: str | None = None
    parts: List[Part]
    metadata: dict[str, Any] | None = None
    index: int = 0
    append: bool | None = None
    lastChunk: bool | None = None


class Task(BaseModel):
    id: str
    sessionId: str | None = None
    status: TaskStatus
    artifacts: List[Artifact] | None = None
    history: List[Message] | None = None
    metadata: dict[str, Any] | None = None


class TaskStatusUpdateEvent(BaseModel):
    id: str
    status: TaskStatus
    final: bool = False
    metadata: dict[str, Any] | None = None


class TaskArtifactUpdateEvent(BaseModel):
    id: str
    artifact: Artifact    
    metadata: dict[str, Any] | None = None


class AuthenticationInfo(BaseModel):
    model_config = ConfigDict(extra="allow")

    schemes: List[str]
    credentials: str | None = None


class PushNotificationConfig(BaseModel):
    url: str
    token: str | None = None
    authentication: AuthenticationInfo | None = None


class TaskIdParams(BaseModel):
    id: str
    metadata: dict[str, Any] | None = None


class TaskQueryParams(TaskIdParams):
    historyLength: int | None = None


class TaskSendParams(BaseModel):
    id: str
    sessionId: str = Field(default_factory=lambda: uuid4().hex)
    message: Message
    acceptedOutputModes: Optional[List[str]] = None
    pushNotification: PushNotificationConfig | None = None
    historyLength: int | None = None
    metadata: dict[str, Any] | None = None


class TaskPushNotificationConfig(BaseModel):
    id: str
    pushNotificationConfig: PushNotificationConfig


## RPC Messages


class JSONRPCMessage(BaseModel):
    jsonrpc: Literal["2.0"] = "2.0"
    id: int | str | None = Field(default_factory=lambda: uuid4().hex)


class JSONRPCRequest(JSONRPCMessage):
    method: str
    params: dict[str, Any] | None = None


class JSONRPCError(BaseModel):
    code: int
    message: str
    data: Any | None = None


class JSONRPCResponse(JSONRPCMessage):
    result: Any | None = None
    error: JSONRPCError | None = None


class SendTaskRequest(JSONRPCRequest):
    method: Literal["tasks/send"] = "tasks/send"
    params: TaskSendParams


class SendTaskResponse(JSONRPCResponse):
    result: Task | None = None


class SendTaskStreamingRequest(JSONRPCRequest):
    method: Literal["tasks/sendSubscribe"] = "tasks/sendSubscribe"
    params: TaskSendParams


class SendTaskStreamingResponse(JSONRPCResponse):
    result: TaskStatusUpdateEvent | TaskArtifactUpdateEvent | None = None


class GetTaskRequest(JSONRPCRequest):
    method: Literal["tasks/get"] = "tasks/get"
    params: TaskQueryParams


class GetTaskResponse(JSONRPCResponse):
    result: Task | None = None


class CancelTaskRequest(JSONRPCRequest):
    method: Literal["tasks/cancel",] = "tasks/cancel"
    params: TaskIdParams


class CancelTaskResponse(JSONRPCResponse):
    result: Task | None = None


class SetTaskPushNotificationRequest(JSONRPCRequest):
    method: Literal["tasks/pushNotification/set",] = "tasks/pushNotification/set"
    params: TaskPushNotificationConfig


class SetTaskPushNotificationResponse(JSONRPCResponse):
    result: TaskPushNotificationConfig | None = None


class GetTaskPushNotificationRequest(JSONRPCRequest):
    method: Literal["tasks/pushNotification/get",] = "tasks/pushNotification/get"
    params: TaskIdParams


class GetTaskPushNotificationResponse(JSONRPCResponse):
    result: TaskPushNotificationConfig | None = None


class TaskResubscriptionRequest(JSONRPCRequest):
    method: Literal["tasks/resubscribe",] = "tasks/resubscribe"
    params: TaskIdParams


A2ARequest = TypeAdapter(
    Annotated[
        Union[
            SendTaskRequest,
            GetTaskRequest,
            CancelTaskRequest,
            SetTaskPushNotificationRequest,
            GetTaskPushNotificationRequest,
            TaskResubscriptionRequest,
            SendTaskStreamingRequest,
        ],
        Field(discriminator="method"),
    ]
)

## Error types


class JSONParseError(JSONRPCError):
    code: int = -32700
    message: str = "Invalid JSON payload"
    data: Any | None = None


class InvalidRequestError(JSONRPCError):
    code: int = -32600
    message: str = "Request payload validation error"
    data: Any | None = None


class MethodNotFoundError(JSONRPCError):
    code: int = -32601
    message: str = "Method not found"
    data: None = None


class InvalidParamsError(JSONRPCError):
    code: int = -32602
    message: str = "Invalid parameters"
    data: Any | None = None


class InternalError(JSONRPCError):
    code: int = -32603
    message: str = "Internal error"
    data: Any | None = None


class TaskNotFoundError(JSONRPCError):
    code: int = -32001
    message: str = "Task not found"
    data: None = None


class TaskNotCancelableError(JSONRPCError):
    code: int = -32002
    message: str = "Task cannot be canceled"
    data: None = None


class PushNotificationNotSupportedError(JSONRPCError):
    code: int = -32003
    message: str = "Push Notification is not supported"
    data: None = None


class UnsupportedOperationError(JSONRPCError):
    code: int = -32004
    message: str = "This operation is not supported"
    data: None = None


class ContentTypeNotSupportedError(JSONRPCError):
    code: int = -32005
    message: str = "Incompatible content types"
    data: None = None


class AgentProvider(BaseModel):
    organization: str
    url: str | None = None


class AgentCapabilities(BaseModel):
    streaming: bool = False
    pushNotifications: bool = False
    stateTransitionHistory: bool = False


class AgentAuthentication(BaseModel):
    schemes: List[str]
    credentials: str | None = None


class AgentSkill(BaseModel):
    id: str
    name: str
    description: str | None = None
    tags: List[str] | None = None
    examples: List[str] | None = None
    inputModes: List[str] | None = None
    outputModes: List[str] | None = None


class AgentCard(BaseModel):
    name: str
    description: str | None = None
    url: str
    provider: AgentProvider | None = None
    version: str
    documentationUrl: str | None = None
    capabilities: AgentCapabilities
    authentication: AgentAuthentication | None = None
    defaultInputModes: List[str] = ["text"]
    defaultOutputModes: List[str] = ["text"]
    skills: List[AgentSkill]


class A2AClientError(Exception):
    pass


class A2AClientHTTPError(A2AClientError):
    def __init__(self, status_code: int, message: str):
        self.status_code = status_code
        self.message = message
        super().__init__(f"HTTP Error {status_code}: {message}")


class A2AClientJSONError(A2AClientError):
    def __init__(self, message: str):
        self.message = message
        super().__init__(f"JSON Error: {message}")


class MissingAPIKeyError(Exception):
    """Exception for missing API key."""

    pass


================================================
FILE: common/client/__init__.py
================================================
from .client import A2AClient
from .card_resolver import A2ACardResolver

__all__ = ["A2AClient", "A2ACardResolver"]



================================================
FILE: common/client/card_resolver.py
================================================
import httpx
from common.types import (
    AgentCard,
    A2AClientJSONError,
)
import json


class A2ACardResolver:
    def __init__(self, base_url, agent_card_path="/.well-known/agent.json"):
        self.base_url = base_url.rstrip("/")
        self.agent_card_path = agent_card_path.lstrip("/")

    def get_agent_card(self) -> AgentCard:
        with httpx.Client() as client:
            response = client.get(self.base_url + "/" + self.agent_card_path)
            response.raise_for_status()
            try:
                return AgentCard(**response.json())
            except json.JSONDecodeError as e:
                raise A2AClientJSONError(str(e)) from e



================================================
FILE: common/client/client.py
================================================
import httpx
from httpx_sse import connect_sse
from typing import Any, AsyncIterable
from common.types import (
    AgentCard,
    GetTaskRequest,
    SendTaskRequest,
    SendTaskResponse,
    JSONRPCRequest,
    GetTaskResponse,
    CancelTaskResponse,
    CancelTaskRequest,
    SetTaskPushNotificationRequest,
    SetTaskPushNotificationResponse,
    GetTaskPushNotificationRequest,
    GetTaskPushNotificationResponse,
    A2AClientHTTPError,
    A2AClientJSONError,
    SendTaskStreamingRequest,
    SendTaskStreamingResponse,
)
import json


class A2AClient:
    def __init__(self, agent_card: AgentCard = None, url: str = None):
        if agent_card:
            self.url = agent_card.url
        elif url:
            self.url = url
        else:
            raise ValueError("Must provide either agent_card or url")

    async def send_task(self, payload: dict[str, Any]) -> SendTaskResponse:
        # self.url += "/a2a"
        print(f"Sending task to {self.url}")
        request = SendTaskRequest(params=payload)
        return SendTaskResponse(**await self._send_request(request))

    async def send_task_streaming(
        self, payload: dict[str, Any]
    ) -> AsyncIterable[SendTaskStreamingResponse]:
        request = SendTaskStreamingRequest(params=payload)
        with httpx.Client(timeout=None) as client:
            with connect_sse(
                client, "POST", self.url, json=request.model_dump()
            ) as event_source:
                try:
                    for sse in event_source.iter_sse():
                        yield SendTaskStreamingResponse(**json.loads(sse.data))
                except json.JSONDecodeError as e:
                    raise A2AClientJSONError(str(e)) from e
                except httpx.RequestError as e:
                    raise A2AClientHTTPError(400, str(e)) from e

    async def _send_request(self, request: JSONRPCRequest) -> dict[str, Any]:
        async with httpx.AsyncClient() as client:
            try:
                # Image generation could take time, adding timeout
                response = await client.post(
                    self.url, json=request.model_dump(), timeout=30
                )
                response.raise_for_status()
                return response.json()
            except httpx.HTTPStatusError as e:
                raise A2AClientHTTPError(e.response.status_code, str(e)) from e
            except json.JSONDecodeError as e:
                raise A2AClientJSONError(str(e)) from e

    async def get_task(self, payload: dict[str, Any]) -> GetTaskResponse:
        request = GetTaskRequest(params=payload)
        return GetTaskResponse(**await self._send_request(request))

    async def cancel_task(self, payload: dict[str, Any]) -> CancelTaskResponse:
        request = CancelTaskRequest(params=payload)
        return CancelTaskResponse(**await self._send_request(request))

    async def set_task_callback(
        self, payload: dict[str, Any]
    ) -> SetTaskPushNotificationResponse:
        request = SetTaskPushNotificationRequest(params=payload)
        return SetTaskPushNotificationResponse(**await self._send_request(request))

    async def get_task_callback(
        self, payload: dict[str, Any]
    ) -> GetTaskPushNotificationResponse:
        request = GetTaskPushNotificationRequest(params=payload)
        return GetTaskPushNotificationResponse(**await self._send_request(request))



================================================
FILE: common/server/__init__.py
================================================
from .server import A2AServer
from .task_manager import TaskManager, InMemoryTaskManager

__all__ = ["A2AServer", "TaskManager", "InMemoryTaskManager"]



================================================
FILE: common/server/server.py
================================================
from starlette.applications import Starlette
from starlette.responses import JSONResponse
from sse_starlette.sse import EventSourceResponse
from starlette.requests import Request
from common.types import (
    A2ARequest,
    JSONRPCResponse,
    InvalidRequestError,
    JSONParseError,
    GetTaskRequest,
    CancelTaskRequest,
    SendTaskRequest,
    SetTaskPushNotificationRequest,
    GetTaskPushNotificationRequest,
    InternalError,
    AgentCard,
    TaskResubscriptionRequest,
    SendTaskStreamingRequest,
)
from pydantic import ValidationError
import json
from typing import AsyncIterable, Any
from common.server.task_manager import TaskManager

import logging

logger = logging.getLogger(__name__)


class A2AServer:
    def __init__(
        self,
        host="0.0.0.0",
        port=5000,
        endpoint="/",
        agent_card: AgentCard = None,
        task_manager: TaskManager = None,
    ):
        self.host = host
        self.port = port
        self.endpoint = endpoint
        self.task_manager = task_manager
        self.agent_card = agent_card
        self.app = Starlette()
        self.app.add_route(self.endpoint, self._process_request, methods=["POST"])
        self.app.add_route(
            "/.well-known/agent.json", self._get_agent_card, methods=["GET"]
        )

    def start(self):
        if self.agent_card is None:
            raise ValueError("agent_card is not defined")

        if self.task_manager is None:
            raise ValueError("request_handler is not defined")

        import uvicorn

        uvicorn.run(self.app, host=self.host, port=self.port)

    def _get_agent_card(self, request: Request) -> JSONResponse:
        return JSONResponse(self.agent_card.model_dump(exclude_none=True))

    async def _process_request(self, request: Request):
        try:
            body = await request.json()
            json_rpc_request = A2ARequest.validate_python(body)

            if isinstance(json_rpc_request, GetTaskRequest):
                result = await self.task_manager.on_get_task(json_rpc_request)
            elif isinstance(json_rpc_request, SendTaskRequest):
                result = await self.task_manager.on_send_task(json_rpc_request)
            elif isinstance(json_rpc_request, SendTaskStreamingRequest):
                result = await self.task_manager.on_send_task_subscribe(
                    json_rpc_request
                )
            elif isinstance(json_rpc_request, CancelTaskRequest):
                result = await self.task_manager.on_cancel_task(json_rpc_request)
            elif isinstance(json_rpc_request, SetTaskPushNotificationRequest):
                result = await self.task_manager.on_set_task_push_notification(json_rpc_request)
            elif isinstance(json_rpc_request, GetTaskPushNotificationRequest):
                result = await self.task_manager.on_get_task_push_notification(json_rpc_request)
            elif isinstance(json_rpc_request, TaskResubscriptionRequest):
                result = await self.task_manager.on_resubscribe_to_task(
                    json_rpc_request
                )
            else:
                logger.warning(f"Unexpected request type: {type(json_rpc_request)}")
                raise ValueError(f"Unexpected request type: {type(request)}")

            return self._create_response(result)

        except Exception as e:
            return self._handle_exception(e)

    def _handle_exception(self, e: Exception) -> JSONResponse:
        if isinstance(e, json.decoder.JSONDecodeError):
            json_rpc_error = JSONParseError()
        elif isinstance(e, ValidationError):
            json_rpc_error = InvalidRequestError(data=json.loads(e.json()))
        else:
            logger.error(f"Unhandled exception: {e}")
            json_rpc_error = InternalError()

        response = JSONRPCResponse(id=None, error=json_rpc_error)
        return JSONResponse(response.model_dump(exclude_none=True), status_code=400)

    def _create_response(self, result: Any) -> JSONResponse | EventSourceResponse:
        if isinstance(result, AsyncIterable):

            async def event_generator(result) -> AsyncIterable[dict[str, str]]:
                async for item in result:
                    yield {"data": item.model_dump_json(exclude_none=True)}

            return EventSourceResponse(event_generator(result))
        elif isinstance(result, JSONRPCResponse):
            return JSONResponse(result.model_dump(exclude_none=True))
        else:
            logger.error(f"Unexpected result type: {type(result)}")
            raise ValueError(f"Unexpected result type: {type(result)}")



================================================
FILE: common/server/task_manager.py
================================================
from abc import ABC, abstractmethod
from typing import Union, AsyncIterable, List
from common.types import Task
from common.types import (
    JSONRPCResponse,
    TaskIdParams,
    TaskQueryParams,
    GetTaskRequest,
    TaskNotFoundError,
    SendTaskRequest,
    CancelTaskRequest,
    TaskNotCancelableError,
    SetTaskPushNotificationRequest,
    GetTaskPushNotificationRequest,
    GetTaskResponse,
    CancelTaskResponse,
    SendTaskResponse,
    SetTaskPushNotificationResponse,
    GetTaskPushNotificationResponse,
    PushNotificationNotSupportedError,
    TaskSendParams,
    TaskStatus,
    TaskState,
    TaskResubscriptionRequest,
    SendTaskStreamingRequest,
    SendTaskStreamingResponse,
    Artifact,
    PushNotificationConfig,
    TaskStatusUpdateEvent,
    JSONRPCError,
    TaskPushNotificationConfig,
    InternalError,
)
from common.server.utils import new_not_implemented_error
import asyncio
import logging

logger = logging.getLogger(__name__)

class TaskManager(ABC):
    @abstractmethod
    async def on_get_task(self, request: GetTaskRequest) -> GetTaskResponse:
        pass

    @abstractmethod
    async def on_cancel_task(self, request: CancelTaskRequest) -> CancelTaskResponse:
        pass

    @abstractmethod
    async def on_send_task(self, request: SendTaskRequest) -> SendTaskResponse:
        pass

    @abstractmethod
    async def on_send_task_subscribe(
        self, request: SendTaskStreamingRequest
    ) -> Union[AsyncIterable[SendTaskStreamingResponse], JSONRPCResponse]:
        pass

    @abstractmethod
    async def on_set_task_push_notification(
        self, request: SetTaskPushNotificationRequest
    ) -> SetTaskPushNotificationResponse:
        pass

    @abstractmethod
    async def on_get_task_push_notification(
        self, request: GetTaskPushNotificationRequest
    ) -> GetTaskPushNotificationResponse:
        pass

    @abstractmethod
    async def on_resubscribe_to_task(
        self, request: TaskResubscriptionRequest
    ) -> Union[AsyncIterable[SendTaskResponse], JSONRPCResponse]:
        pass


class InMemoryTaskManager(TaskManager):
    def __init__(self):
        self.tasks: dict[str, Task] = {}
        self.push_notification_infos: dict[str, PushNotificationConfig] = {}
        self.lock = asyncio.Lock()
        self.task_sse_subscribers: dict[str, List[asyncio.Queue]] = {}
        self.subscriber_lock = asyncio.Lock()

    async def on_get_task(self, request: GetTaskRequest) -> GetTaskResponse:
        logger.info(f"Getting task {request.params.id}")
        task_query_params: TaskQueryParams = request.params

        async with self.lock:
            task = self.tasks.get(task_query_params.id)
            if task is None:
                return GetTaskResponse(id=request.id, error=TaskNotFoundError())

            task_result = self.append_task_history(
                task, task_query_params.historyLength
            )

        return GetTaskResponse(id=request.id, result=task_result)

    async def on_cancel_task(self, request: CancelTaskRequest) -> CancelTaskResponse:
        logger.info(f"Cancelling task {request.params.id}")
        task_id_params: TaskIdParams = request.params

        async with self.lock:
            task = self.tasks.get(task_id_params.id)
            if task is None:
                return CancelTaskResponse(id=request.id, error=TaskNotFoundError())

        return CancelTaskResponse(id=request.id, error=TaskNotCancelableError())

    @abstractmethod
    async def on_send_task(self, request: SendTaskRequest) -> SendTaskResponse:
        pass

    @abstractmethod
    async def on_send_task_subscribe(
        self, request: SendTaskStreamingRequest
    ) -> Union[AsyncIterable[SendTaskStreamingResponse], JSONRPCResponse]:
        pass

    async def set_push_notification_info(self, task_id: str, notification_config: PushNotificationConfig):
        async with self.lock:
            task = self.tasks.get(task_id)
            if task is None:
                raise ValueError(f"Task not found for {task_id}")

            self.push_notification_infos[task_id] = notification_config

        return
    
    async def get_push_notification_info(self, task_id: str) -> PushNotificationConfig:
        async with self.lock:
            task = self.tasks.get(task_id)
            if task is None:
                raise ValueError(f"Task not found for {task_id}")

            return self.push_notification_infos[task_id]
            
        return
    
    async def has_push_notification_info(self, task_id: str) -> bool:
        async with self.lock:
            return task_id in self.push_notification_infos
            

    async def on_set_task_push_notification(
        self, request: SetTaskPushNotificationRequest
    ) -> SetTaskPushNotificationResponse:
        logger.info(f"Setting task push notification {request.params.id}")
        task_notification_params: TaskPushNotificationConfig = request.params

        try:
            await self.set_push_notification_info(task_notification_params.id, task_notification_params.pushNotificationConfig)
        except Exception as e:
            logger.error(f"Error while setting push notification info: {e}")
            return JSONRPCResponse(
                id=request.id,
                error=InternalError(
                    message="An error occurred while setting push notification info"
                ),
            )
            
        return SetTaskPushNotificationResponse(id=request.id, result=task_notification_params)

    async def on_get_task_push_notification(
        self, request: GetTaskPushNotificationRequest
    ) -> GetTaskPushNotificationResponse:
        logger.info(f"Getting task push notification {request.params.id}")
        task_params: TaskIdParams = request.params

        try:
            notification_info = await self.get_push_notification_info(task_params.id)
        except Exception as e:
            logger.error(f"Error while getting push notification info: {e}")
            return GetTaskPushNotificationResponse(
                id=request.id,
                error=InternalError(
                    message="An error occurred while getting push notification info"
                ),
            )
        
        return GetTaskPushNotificationResponse(id=request.id, result=TaskPushNotificationConfig(id=task_params.id, pushNotificationConfig=notification_info))

    async def upsert_task(self, task_send_params: TaskSendParams) -> Task:
        logger.info(f"Upserting task {task_send_params.id}")
        async with self.lock:
            task = self.tasks.get(task_send_params.id)
            if task is None:
                task = Task(
                    id=task_send_params.id,
                    sessionId = task_send_params.sessionId,
                    messages=[task_send_params.message],
                    status=TaskStatus(state=TaskState.SUBMITTED),
                    history=[task_send_params.message],
                )
                self.tasks[task_send_params.id] = task
            else:
                task.history.append(task_send_params.message)

            return task

    async def on_resubscribe_to_task(
        self, request: TaskResubscriptionRequest
    ) -> Union[AsyncIterable[SendTaskStreamingResponse], JSONRPCResponse]:
        return new_not_implemented_error(request.id)

    async def update_store(
        self, task_id: str, status: TaskStatus, artifacts: list[Artifact]
    ) -> Task:
        async with self.lock:
            try:
                task = self.tasks[task_id]
            except KeyError:
                logger.error(f"Task {task_id} not found for updating the task")
                raise ValueError(f"Task {task_id} not found")

            task.status = status

            if status.message is not None:
                task.history.append(status.message)

            if artifacts is not None:
                if task.artifacts is None:
                    task.artifacts = []
                task.artifacts.extend(artifacts)

            return task

    def append_task_history(self, task: Task, historyLength: int | None):
        new_task = task.model_copy()
        if historyLength is not None and historyLength > 0:
            new_task.history = new_task.history[-historyLength:]
        else:
            new_task.history = []

        return new_task        

    async def setup_sse_consumer(self, task_id: str, is_resubscribe: bool = False):
        async with self.subscriber_lock:
            if task_id not in self.task_sse_subscribers:
                if is_resubscribe:
                    raise ValueError("Task not found for resubscription")
                else:
                    self.task_sse_subscribers[task_id] = []

            sse_event_queue = asyncio.Queue(maxsize=0) # <=0 is unlimited
            self.task_sse_subscribers[task_id].append(sse_event_queue)
            return sse_event_queue

    async def enqueue_events_for_sse(self, task_id, task_update_event):
        async with self.subscriber_lock:
            if task_id not in self.task_sse_subscribers:
                return

            current_subscribers = self.task_sse_subscribers[task_id]
            for subscriber in current_subscribers:
                await subscriber.put(task_update_event)

    async def dequeue_events_for_sse(
        self, request_id, task_id, sse_event_queue: asyncio.Queue
    ) -> AsyncIterable[SendTaskStreamingResponse] | JSONRPCResponse:
        try:
            while True:                
                event = await sse_event_queue.get()
                if isinstance(event, JSONRPCError):
                    yield SendTaskStreamingResponse(id=request_id, error=event)
                    break
                                                
                yield SendTaskStreamingResponse(id=request_id, result=event)
                if isinstance(event, TaskStatusUpdateEvent) and event.final:
                    break
        finally:
            async with self.subscriber_lock:
                if task_id in self.task_sse_subscribers:
                    self.task_sse_subscribers[task_id].remove(sse_event_queue)




================================================
FILE: common/server/utils.py
================================================
from common.types import (
    JSONRPCResponse,
    ContentTypeNotSupportedError,
    UnsupportedOperationError,
)
from typing import List


def are_modalities_compatible(
    server_output_modes: List[str], client_output_modes: List[str]
):
    """Modalities are compatible if they are both non-empty
    and there is at least one common element."""
    if client_output_modes is None or len(client_output_modes) == 0:
        return True

    if server_output_modes is None or len(server_output_modes) == 0:
        return True

    return any(x in server_output_modes for x in client_output_modes)


def new_incompatible_types_error(request_id):
    return JSONRPCResponse(id=request_id, error=ContentTypeNotSupportedError())


def new_not_implemented_error(request_id):
    return JSONRPCResponse(id=request_id, error=UnsupportedOperationError())



================================================
FILE: common/utils/in_memory_cache.py
================================================
"""In Memory Cache utility."""

import threading
import time
from typing import Any, Dict, Optional


class InMemoryCache:
    """A thread-safe Singleton class to manage cache data.

    Ensures only one instance of the cache exists across the application.
    """

    _instance: Optional["InMemoryCache"] = None
    _lock: threading.Lock = threading.Lock()
    _initialized: bool = False

    def __new__(cls):
        """Override __new__ to control instance creation (Singleton pattern).

        Uses a lock to ensure thread safety during the first instantiation.

        Returns:
            The singleton instance of InMemoryCache.
        """
        if cls._instance is None:
            with cls._lock:
                if cls._instance is None:
                    cls._instance = super().__new__(cls)
        return cls._instance

    def __init__(self):
        """Initialize the cache storage.

        Uses a flag (_initialized) to ensure this logic runs only on the very first
        creation of the singleton instance.
        """
        if not self._initialized:
            with self._lock:
                if not self._initialized:
                    # print("Initializing SessionCache storage")
                    self._cache_data: Dict[str, Dict[str, Any]] = {}
                    self._ttl: Dict[str, float] = {}
                    self._data_lock: threading.Lock = threading.Lock()
                    self._initialized = True

    def set(self, key: str, value: Any, ttl: Optional[int] = None) -> None:
        """Set a key-value pair.

        Args:
            key: The key for the data.
            value: The data to store.
            ttl: Time to live in seconds. If None, data will not expire.
        """
        with self._data_lock:
            self._cache_data[key] = value

            if ttl is not None:
                self._ttl[key] = time.time() + ttl
            else:
                if key in self._ttl:
                    del self._ttl[key]

    def get(self, key: str, default: Any = None) -> Any:
        """Get the value associated with a key.

        Args:
            key: The key for the data within the session.
            default: The value to return if the session or key is not found.

        Returns:
            The cached value, or the default value if not found.
        """
        with self._data_lock:
            if key in self._ttl and time.time() > self._ttl[key]:
                del self._cache_data[key]
                del self._ttl[key]
                return default
            return self._cache_data.get(key, default)

    def delete(self, key: str) -> None:
        """Delete a specific key-value pair from a cache.

        Args:
            key: The key to delete.

        Returns:
            True if the key was found and deleted, False otherwise.
        """

        with self._data_lock:
            if key in self._cache_data:
                del self._cache_data[key]
                if key in self._ttl:
                    del self._ttl[key]
                return True
            return False

    def clear(self) -> bool:
        """Remove all data.

        Returns:
            True if the data was cleared, False otherwise.
        """
        with self._data_lock:
            self._cache_data.clear()
            self._ttl.clear()
            return True
        return False



================================================
FILE: common/utils/push_notification_auth.py
================================================
from jwcrypto import jwk
import uuid
from starlette.responses import JSONResponse
from starlette.requests import Request
from typing import Any

import jwt
import time
import json
import hashlib
import httpx
import logging

from jwt import PyJWK, PyJWKClient

logger = logging.getLogger(__name__)
AUTH_HEADER_PREFIX = 'Bearer '

class PushNotificationAuth:
    def _calculate_request_body_sha256(self, data: dict[str, Any]):
        """Calculates the SHA256 hash of a request body.

        This logic needs to be same for both the agent who signs the payload and the client verifier.
        """
        body_str = json.dumps(
            data,
            ensure_ascii=False,
            allow_nan=False,
            indent=None,
            separators=(",", ":"),
        )
        return hashlib.sha256(body_str.encode()).hexdigest()

class PushNotificationSenderAuth(PushNotificationAuth):
    def __init__(self):
        self.public_keys = []
        self.private_key_jwk: PyJWK = None

    @staticmethod
    async def verify_push_notification_url(url: str) -> bool:
        async with httpx.AsyncClient(timeout=10) as client:
            try:
                validation_token = str(uuid.uuid4())
                response = await client.get(
                    url,
                    params={"validationToken": validation_token}
                )
                response.raise_for_status()
                is_verified = response.text == validation_token

                logger.info(f"Verified push-notification URL: {url} => {is_verified}")            
                return is_verified                
            except Exception as e:
                logger.warning(f"Error during sending push-notification for URL {url}: {e}")

        return False

    def generate_jwk(self):
        key = jwk.JWK.generate(kty='RSA', size=2048, kid=str(uuid.uuid4()), use="sig")
        self.public_keys.append(key.export_public(as_dict=True))
        self.private_key_jwk = PyJWK.from_json(key.export_private())
    
    def handle_jwks_endpoint(self, _request: Request):
        """Allow clients to fetch public keys.
        """
        return JSONResponse({
            "keys": self.public_keys
        })
    
    def _generate_jwt(self, data: dict[str, Any]):
        """JWT is generated by signing both the request payload SHA digest and time of token generation.

        Payload is signed with private key and it ensures the integrity of payload for client.
        Including iat prevents from replay attack.
        """
        
        iat = int(time.time())

        return jwt.encode(
            {"iat": iat, "request_body_sha256": self._calculate_request_body_sha256(data)},
            key=self.private_key_jwk,
            headers={"kid": self.private_key_jwk.key_id},
            algorithm="RS256"
        )

    async def send_push_notification(self, url: str, data: dict[str, Any]):
        jwt_token = self._generate_jwt(data)
        headers = {'Authorization': f"Bearer {jwt_token}"}
        async with httpx.AsyncClient(timeout=10) as client: 
            try:
                response = await client.post(
                    url,
                    json=data,
                    headers=headers
                )
                response.raise_for_status()
                logger.info(f"Push-notification sent for URL: {url}")                            
            except Exception as e:
                logger.warning(f"Error during sending push-notification for URL {url}: {e}")

class PushNotificationReceiverAuth(PushNotificationAuth):
    def __init__(self):
        self.public_keys_jwks = []
        self.jwks_client = None

    async def load_jwks(self, jwks_url: str):
        self.jwks_client = PyJWKClient(jwks_url)
    
    async def verify_push_notification(self, request: Request) -> bool:
        auth_header = request.headers.get("Authorization")
        if not auth_header or not auth_header.startswith(AUTH_HEADER_PREFIX):
            print("Invalid authorization header")
            return False
        
        token = auth_header[len(AUTH_HEADER_PREFIX):]
        signing_key = self.jwks_client.get_signing_key_from_jwt(token)

        decode_token = jwt.decode(
            token,
            signing_key,
            options={"require": ["iat", "request_body_sha256"]},
            algorithms=["RS256"],
        )

        actual_body_sha256 = self._calculate_request_body_sha256(await request.json())
        if actual_body_sha256 != decode_token["request_body_sha256"]:
            # Payload signature does not match the digest in signed token.
            raise ValueError("Invalid request body")
        
        if time.time() - decode_token["iat"] > 60 * 5:
            # Do not allow push-notifications older than 5 minutes.
            # This is to prevent replay attack.
            raise ValueError("Token is expired")
        
        return True



================================================
FILE: host_agent/__init__.py
================================================



================================================
FILE: host_agent/agent.py
================================================
import logging
import os
import asyncio # For running the discovery at startup

from google.adk.agents import Agent
from google.adk.agents.callback_context import CallbackContext
from google.adk.tools import ToolContext # For callback type hints

from typing import Dict, Any, List, Optional # Added List, Optional

from dotenv import load_dotenv

# Environment Loading (as before)
dotenv_path = os.path.join(os.path.dirname(__file__), '..', '.env')
load_dotenv(dotenv_path=dotenv_path, override=True)

# Import the new tool and discovery cache
try:
    from .tools import delegate_tool, DISCOVERED_SPECIALIST_AGENTS, initialize_specialist_agents_discovery
except ImportError as e:
    logging.critical(f"Failed to import tools for HostAgent: {e}")
    delegate_tool = None
    DISCOVERED_SPECIALIST_AGENTS = {}
    initialize_specialist_agents_discovery = None # Define it to avoid NameError later

logger = logging.getLogger(__name__)
MODEL_ID_LIVE = os.getenv("LIVE_SERVER_MODEL", "gemini-2.0-flash-live-001")

# --- Dynamic Instruction Builder ---
def get_host_agent_instruction() -> str:
    base_instruction = (
        "You are a friendly financial assistant interacting via voice and text. "
        "Your primary function is to help users with financial queries.\n"
        "You have access to a set of specialist agents. "
        "Based on the user's request, determine if a specialist agent is suitable. "
        "If so, use the 'delegate_task_to_specialist' tool. Provide the specialist's name and the user's query (e.g., just the stock symbol for stock lookups).\n"
        "If the user asks for a stock price (e.g., 'price of GOOGL', 'how is MSFT doing?'), "
        "delegate to the specialist agent whose description mentions stock prices or financial data. The 'query_payload' for this tool should be the stock ticker symbol.\n"
        "After the specialist responds:\n"
        "  - If successful, relay the information clearly (e.g., 'Microsoft (MSFT) is currently trading at $150.25 USD.').\n"
        "  - If there's an error, inform the user politely (e.g., 'Sorry, I couldn't retrieve that information right now.').\n"
        "Handle other conversational turns naturally.\n\n"
        "Available Specialist Agents:\n"
    )
    if not DISCOVERED_SPECIALIST_AGENTS:
        base_instruction += "- None discovered. You must handle all queries yourself if possible, or state you cannot fulfill the request.\n"
    else:
        for name, card in DISCOVERED_SPECIALIST_AGENTS.items():
            description = card.description or "No description provided."
            # Try to get a skill description if top-level description is generic
            if "Provides current stock price information" in description and card.skills: # Heuristic
                skill_desc = next((s.description for s in card.skills if "stock" in s.name.lower() or (s.description and "stock" in s.description.lower())), None)
                if skill_desc : description = skill_desc

            base_instruction += f"- Name: '{name}', Description: '{description}'\n"
    
    logger.debug(f"Generated HostAgent Instruction:\n{base_instruction}")
    return base_instruction

# --- Agent Definition ---
host_agent: Optional[Agent] = None

async def create_host_agent() -> Optional[Agent]:
    """
    Asynchronously initializes specialist agents and creates the HostAgent.
    Should be called once at application startup.
    """
    global host_agent # Allow modification of the global host_agent
    if initialize_specialist_agents_discovery:
        await initialize_specialist_agents_discovery()
    else:
        logger.error("initialize_specialist_agents_discovery function not available. Cannot discover specialists.")
        return None

    if not delegate_tool:
        logger.critical("Host Agent could not be created because 'delegate_tool' failed to load.")
        return None

    current_instruction = get_host_agent_instruction()
    host_agent = Agent(
        name="HostAgentLiveDynamic",
        model=MODEL_ID_LIVE,
        description="User-facing agent that dynamically delegates to discovered specialist agents.",
        instruction=current_instruction,
        tools=[delegate_tool], # Use the new dynamic delegation tool
    )
    logger.info(f"ADK Host Agent '{host_agent.name}' created with model '{MODEL_ID_LIVE}'.")
    return host_agent

# Note: The actual creation of the host_agent instance will happen
# in the live_server.py by calling create_host_agent().
# This ensures discovery happens in an async context.


================================================
FILE: host_agent/tools.py
================================================
import os
import uuid
import logging
import json
from typing import Dict, Any, List, Optional # Added List, Optional
import httpx # For fetching agent card

# ADK Imports
from google.adk.tools import ToolContext, FunctionTool

# A2A Imports
try:
    from common.client import A2AClient, A2ACardResolver # Added A2ACardResolver
    from common.types import (
        TaskSendParams, Message, TextPart, TaskState, DataPart,
        A2AClientHTTPError, A2AClientJSONError, AgentCard # Added AgentCard
    )
except ImportError:
    raise ImportError("Could not import A2A common library...")

logger = logging.getLogger(__name__)

# --- Specialist Agent Configuration ---
# Instead of full URL, we'll use base URLs to discover Agent Cards
# This could be a list if you have multiple specialists
SPECIALIST_AGENT_BASE_URLS_STR = os.getenv("SPECIALIST_AGENT_BASE_URLS", "http://localhost:8001") # Default to stock agent
SPECIALIST_AGENT_BASE_URLS = [url.strip() for url in SPECIALIST_AGENT_BASE_URLS_STR.split(',') if url.strip()]

# Cache for discovered agent cards, keyed by agent name (or another unique ID from the card)
DISCOVERED_SPECIALIST_AGENTS: Dict[str, AgentCard] = {}

async def initialize_specialist_agents_discovery():
    """
    Fetches Agent Cards from configured specialist base URLs and populates the cache.
    This should be called once at HostAgent startup.
    """
    if not SPECIALIST_AGENT_BASE_URLS:
        logger.warning("No specialist agent base URLs configured. HostAgent cannot delegate via A2A.")
        return

    logger.info(f"Discovering specialist agents from base URLs: {SPECIALIST_AGENT_BASE_URLS}")
    async with httpx.AsyncClient() as client:
        for base_url in SPECIALIST_AGENT_BASE_URLS:
            card_url = f"{base_url.rstrip('/')}/.well-known/agent.json"
            try:
                logger.info(f"Fetching Agent Card from: {card_url}")
                # In a real A2A client, you'd use A2ACardResolver,
                # but for simplicity in this tool, direct httpx get.
                # resolver = A2ACardResolver(base_url=base_url) # This is synchronous, needs async wrapper or use httpx
                
                response = await client.get(card_url, timeout=10.0)
                response.raise_for_status()
                card_data = response.json()
                agent_card = AgentCard(**card_data)

                if not agent_card.name:
                    logger.error(f"Agent Card from {card_url} is missing a name. Skipping.")
                    continue
                if not agent_card.url: # This is the A2A endpoint URL
                    logger.error(f"Agent Card for '{agent_card.name}' from {card_url} is missing the A2A 'url'. Skipping.")
                    continue

                DISCOVERED_SPECIALIST_AGENTS[agent_card.name] = agent_card
                logger.info(f"Discovered Specialist Agent: '{agent_card.name}' - A2A URL: {agent_card.url}")
                logger.debug(f"  Description: {agent_card.description}")
                logger.debug(f"  Skills: {[s.name for s in agent_card.skills]}")

            except httpx.HTTPStatusError as e:
                logger.error(f"Failed to fetch Agent Card from {card_url}: HTTP {e.response.status_code}")
            except (httpx.RequestError, json.JSONDecodeError, ValueError) as e: # ValueError for Pydantic validation
                logger.error(f"Error processing Agent Card from {card_url}: {e}", exc_info=True)
    
    if not DISCOVERED_SPECIALIST_AGENTS:
        logger.warning("No specialist agents were successfully discovered.")


async def delegate_task_to_specialist(
    specialist_agent_name: str,
    query_payload: str, # Could be a JSON string for more complex inputs
    tool_context: ToolContext
) -> Dict[str, Any]:
    """
    Dynamically delegates a task to a discovered specialist agent using A2A.

    Args:
        specialist_agent_name: The name of the specialist agent (must match a discovered AgentCard.name).
        query_payload: The core query or data to send to the specialist (e.g., stock symbol, or JSON string of params).
        tool_context: The ADK ToolContext.

    Returns:
        A dictionary containing the specialist's processed result or an error.
    """
    logger.info(f"ADK Tool: 'delegate_task_to_specialist' for '{specialist_agent_name}' with query: '{query_payload[:100]}...'")

    if specialist_agent_name not in DISCOVERED_SPECIALIST_AGENTS:
        err_msg = f"Specialist agent '{specialist_agent_name}' not found or not discovered."
        logger.error(f"ADK Tool: {err_msg}")
        return {"status": "error", "message": err_msg}

    agent_card = DISCOVERED_SPECIALIST_AGENTS[specialist_agent_name]
    specialist_a2a_url = agent_card.url # Get A2A endpoint from the card

    a2a_session_id = tool_context._invocation_context.session.id
    a2a_task_id = uuid.uuid4().hex

    # For simplicity, assume query_payload is text for now.
    # For more complex interactions, query_payload could be a JSON string
    # that gets parsed into multiple A2A MessageParts.
    try:
        # Attempt to parse if it's JSON, otherwise treat as text
        parts_data = json.loads(query_payload)
        if isinstance(parts_data, dict): # Expecting a dict for DataPart
            a2a_parts = [DataPart(data=parts_data)]
        else: # Fallback to text if not a dict
            a2a_parts = [TextPart(text=str(query_payload))]
    except json.JSONDecodeError:
        a2a_parts = [TextPart(text=query_payload)]


    a2a_client = A2AClient(url=specialist_a2a_url) # Use URL from card
    task_params = TaskSendParams(
        id=a2a_task_id,
        sessionId=a2a_session_id,
        message=Message(
            role="user",
            parts=a2a_parts
        )
    )

    logger.info(f"ADK Tool: Sending A2A task to '{specialist_agent_name}' at {specialist_a2a_url}...")
    logger.debug(f"ADK Tool: A2A TaskSendParams: {task_params.model_dump_json(indent=2)}")

    try:
        a2a_response = await a2a_client.send_task(task_params.model_dump())

        if a2a_response.error:
            error_msg = f"A2A protocol error from '{specialist_agent_name}': {a2a_response.error.message} (Code: {a2a_response.error.code})"
            logger.error(f"ADK Tool: {error_msg}")
            return {"status": "error", "message": error_msg, "specialist_name": specialist_agent_name}

        if a2a_response.result:
            task_result = a2a_response.result
            logger.debug(f"ADK Tool: A2A Task Result from '{specialist_agent_name}', State: {task_result.status.state}")

            if task_result.status.state == TaskState.COMPLETED and task_result.artifacts:
                # Generic artifact extraction - you might want to make this more specific
                # if different specialists return different artifact structures.
                # For now, just return the first DataPart found.
                for artifact in task_result.artifacts:
                     if artifact.parts:
                         for part in artifact.parts:
                             if isinstance(part, DataPart):
                                 data = part.data
                                 logger.info(f"ADK Tool: Successfully retrieved data from '{specialist_agent_name}': {data}")
                                 return {"status": "success", "data": data, "specialist_name": specialist_agent_name}
                logger.warning(f"ADK Tool: Task from '{specialist_agent_name}' completed but no suitable DataPart artifact found.")
                return {"status": "error", "message": "Received no parsable data artifact from specialist.", "specialist_name": specialist_agent_name}

            elif task_result.status.state == TaskState.FAILED and task_result.artifacts:
                 for artifact in task_result.artifacts:
                     if artifact.name == "error_details" and artifact.parts:
                          for part in artifact.parts:
                              if isinstance(part, DataPart) and "error" in part.data:
                                  error_msg = part.data["error"]
                                  logger.error(f"ADK Tool: Specialist '{specialist_agent_name}' task failed: {error_msg}")
                                  return {"status": "error", "message": f"Specialist Error: {error_msg}", "specialist_name": specialist_agent_name}
                 logger.error(f"ADK Tool: Specialist '{specialist_agent_name}' task failed, but couldn't parse error artifact.")
                 return {"status": "error", "message": "Specialist reported failure with unclear details.", "specialist_name": specialist_agent_name}
            else:
                 logger.error(f"ADK Tool: Specialist '{specialist_agent_name}' task ended in unexpected state: {task_result.status.state}")
                 return {"status": "error", "message": f"Specialist agent '{specialist_agent_name}' ended in state: {task_result.status.state}", "specialist_name": specialist_agent_name}
        else:
            logger.error(f"ADK Tool: Received empty successful response from A2A server '{specialist_agent_name}'.")
            return {"status": "error", "message": "Empty response from specialist agent.", "specialist_name": specialist_agent_name}

    except A2AClientHTTPError as http_err:
         logger.error(f"ADK Tool: HTTP Error calling specialist agent '{specialist_agent_name}': {http_err.status_code} - {http_err.message}", exc_info=True)
         return {"status": "error", "message": f"Network error with '{specialist_agent_name}': {http_err.status_code}", "specialist_name": specialist_agent_name}
    except Exception as e:
        logger.error(f"ADK Tool: Unexpected error during A2A call to '{specialist_agent_name}': {e}", exc_info=True)
        return {"status": "error", "message": f"An unexpected error occurred with '{specialist_agent_name}': {str(e)}", "specialist_name": specialist_agent_name}


# Create the ADK FunctionTool
delegate_tool = FunctionTool(
    func=delegate_task_to_specialist,
    # Name for the LLM to call
)

logger.info("‚úÖ ADK Tool for dynamic A2A delegation defined.")


================================================
FILE: mcp_servers/stock_mcp_server/server.py
================================================
import logging
import asyncio
from mcp.server.fastmcp import FastMCP
import finnhub
import sys
import json
import os
from dotenv import load_dotenv

# Determine the absolute path to the .env file in the project root
# __file__ is the path to the current script (server.py)
# os.path.dirname(__file__) is the directory of server.py
# os.path.join(..., "..", "..") goes up two directories to the project root
project_root_env = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", "..", ".env"))
load_dotenv(project_root_env, override=True) # Load variables from .env file

# --- Configuration ---
# Basic logging setup
logging.basicConfig(level=logging.DEBUG, # <--- Change level to DEBUG for more detail
                    stream=sys.stderr,
                    format='%(asctime)s - %(name)s - %(levelname)s - MCP_SERVER - %(message)s')
logger = logging.getLogger(__name__)

# --- Finnhub Client Initialization ---
FINNHUB_API_KEY = os.getenv("FINNHUB_API_KEY")
if not FINNHUB_API_KEY:
    logger.warning("FINNHUB_API_KEY environment variable not found. Stock price queries will use mock data.")
    
finnhub_client = finnhub.Client(api_key=FINNHUB_API_KEY or "")
if FINNHUB_API_KEY:
    logger.info(f"Finnhub client initialized with API key: {FINNHUB_API_KEY[:3]}...{FINNHUB_API_KEY[-3:] if len(FINNHUB_API_KEY) > 6 else ''}")
else:
    logger.info("Finnhub client initialized without API key")

# --- FastMCP Server Initialization ---
# Creates a customizable MCP server named "Stock Price Server"
logger.info("Initializing FastMCP server...")
mcp = FastMCP("Stock Price Server") # Name used during initialization

# --- Tool Functions (using decorators) ---

@mcp.tool()
async def get_current_stock_price(symbol: str) -> dict:
    """
    Retrieve the current stock price for the given ticker symbol.
    Returns a dictionary containing the price and currency, or an error message.
    """
    # Log the incoming arguments (part of the MCP request's params)
    logger.debug(f"Tool 'get_current_stock_price' called with args: {{'symbol': '{symbol}'}}")

    # Check MOCK_STOCK_API environment variable
    mock_api_enabled = os.getenv("MOCK_STOCK_API", "False").lower() == "true"

    if mock_api_enabled:
        logger.info("MOCK_STOCK_API is enabled. Returning mock data.")
        result = {
            "symbol": symbol.upper(),
            "price": 123.45,
            "currency": "USD",
            "note": "Mock data (MOCK_STOCK_API enabled)"
        }
        logger.debug(f"Tool 'get_current_stock_price' returning result: {json.dumps(result, indent=2)}")
        return result

    # If MOCK_STOCK_API is not true, proceed with actual API call
    try:
        # Use Finnhub API to get stock quote
        quote = finnhub_client.quote(symbol.upper())
        
        # Check if we have a valid quote
        if quote and 'c' in quote and quote['c'] > 0:
            price = quote['c']  # Current price
            result = {
                "symbol": symbol.upper(),
                "price": round(price, 2),
                "currency": "USD",  # Finnhub uses USD by default
                "previous_close": quote.get('pc', None)  # Previous close price
            }
            logger.info(f"Tool: Successfully found price {result['price']} USD for {symbol} using Finnhub.")
        else:
            # If no valid price in quote, use previous close if available
            if quote and 'pc' in quote and quote['pc'] > 0:
                price = quote['pc']  # Previous close
                result = {
                    "symbol": symbol.upper(),
                    "price": round(price, 2),
                    "currency": "USD",
                    "note": "Using previous close price"
                }
                logger.info(f"Tool: Using previous close price {result['price']} USD for {symbol}.")
            else:
                # No valid data from Finnhub
                logger.warning(f"Tool: No current price data found for symbol {symbol}. Returning mock data.")
                result = {
                    "symbol": symbol.upper(),
                    "price": 123.45,
                    "currency": "USD",
                    "note": "Mock data: Price not found via Finnhub"
                }

    except Exception as e:
        logger.error(f"Tool: Error fetching price for {symbol} from Finnhub: {e}. Returning mock data.", exc_info=False)
        result = {
            "symbol": symbol.upper(),
            "price": 123.45,
            "currency": "USD",
            "note": f"Mock data: Finnhub API error ({type(e).__name__})"
        }

    # Log the result dictionary (which will be the MCP response's result field)
    logger.debug(f"Tool 'get_current_stock_price' returning result: {json.dumps(result, indent=2)}")
    return result


# --- Main Execution ---
if __name__ == "__main__":
    # --- To run the MCP server (original behavior) ---
    logger.info("Starting FastMCP Stock Price Server...")
    mcp.run() # defaults to stdio transport
    logger.info("FastMCP Stock Price Server stopped.")



================================================
FILE: specialist_agents/stock_info_agent/__init__.py
================================================



================================================
FILE: specialist_agents/stock_info_agent/__main__.py
================================================
import os
import logging
import click
from dotenv import load_dotenv

# A2A Imports from common library
from common.server import A2AServer
from common.types import AgentCard, AgentCapabilities, AgentSkill

# Local Imports
from .task_manager import StockInfoTaskManager

# --- Configuration ---
# Load .env file from the project root
dotenv_path = os.path.join(os.path.dirname(__file__), '..', '..', '.env')
load_dotenv(dotenv_path=dotenv_path, override=True)

logging.basicConfig(level=os.getenv('LOG_LEVEL', 'INFO').upper(),
                    format='%(asctime)s - %(name)s - %(levelname)s - A2A_SERVER - %(message)s')
logger = logging.getLogger(__name__)

# --- Environment Variable Defaults for Click Options ---
# These are read once at module load time after .env is processed.
# Click options will use these values for defaults and to determine 'required' status.
ENV_STOCK_INFO_AGENT_A2A_SERVER_HOST = os.getenv("STOCK_INFO_AGENT_A2A_SERVER_HOST")
ENV_STOCK_INFO_AGENT_A2A_SERVER_PORT = os.getenv("STOCK_INFO_AGENT_A2A_SERVER_PORT")
ENV_STOCK_MCP_SERVER_PATH = os.getenv("STOCK_MCP_SERVER_PATH")

# --- Main Function ---
@click.command()
@click.option("--host",
              default=ENV_STOCK_INFO_AGENT_A2A_SERVER_HOST,
              help="Host to bind the A2A server to. Reads from STOCK_INFO_AGENT_A2A_SERVER_HOST environment variable.",
              required=ENV_STOCK_INFO_AGENT_A2A_SERVER_HOST is None,
              show_default=True)
@click.option("--port",
              default=ENV_STOCK_INFO_AGENT_A2A_SERVER_PORT,
              type=int,
              help="Port to bind the A2A server to. Reads from STOCK_INFO_AGENT_A2A_SERVER_PORT environment variable.",
              required=ENV_STOCK_INFO_AGENT_A2A_SERVER_PORT is None,
              show_default=True)
@click.option("--mcp-server-path",
              default=ENV_STOCK_MCP_SERVER_PATH,
              help="Absolute path to the stock_mcp_server.py script. Reads from STOCK_MCP_SERVER_PATH environment variable.",
              required=ENV_STOCK_MCP_SERVER_PATH is None,
              show_default=True # Added for consistency, Click will show the default if available.
             )


def main(host: str, port: int, mcp_server_path: str):
    """Starts the StockInfoAgent A2A Server."""
    logger.info("Starting StockInfoAgent A2A Server...")
    logger.info(f"  Host: {host}")
    logger.info(f"  Port: {port}")
    logger.info(f"  MCP Server Script Path: {mcp_server_path}")

    # --- Convert MCP Server Path to Absolute if Necessary ---
    if not os.path.isabs(mcp_server_path):
        logger.info(f"MCP server path '{mcp_server_path}' is relative. Converting to absolute path.")
        # Assume the relative path is from the project root or current working directory.
        # For consistency, let's resolve it relative to the project root.
        # The .env file is at project_root/.env, and this script is at project_root/specialist_agents/stock_info_agent/__main__.py
        # So, to get to the project root from this script's directory: os.path.dirname(__file__)/../../
        project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..'))
        mcp_server_path = os.path.join(project_root, mcp_server_path)
        logger.info(f"Resolved MCP server path to: {mcp_server_path}")
    
    # --- Verify MCP Server Path ---
    if not os.path.exists(mcp_server_path):
        logger.error(f"Error: MCP server script not found at: '{mcp_server_path}'")
        click.echo(f"Error: MCP server script not found at: '{mcp_server_path}'", err=True)
        return

    try:
        # --- Define Agent Card Programmatically ---
        capabilities = AgentCapabilities(streaming=False) # Synchronous agent
        skill = AgentSkill(
            id="get_stock_price_skill",
            name="Get Stock Price",
            description="Retrieves the current price and currency for a given stock ticker symbol.",
            tags=["finance", "stocks", "price lookup"],
            examples=["What is the price of GOOGL?", "Stock price for MSFT"],
            outputModes=["application/json"] # Skill specific output
        )
        agent_card = AgentCard(
            name="StockInfoAgent",
            description="Provides current stock price information using the yfinance library via MCP.",
            url=f"http://{host}:{port}", # Define the A2A endpoint path
            provider={"organization": "ProjectHorizon"},
            version="1.0.0",
            defaultInputModes=["text/plain"],
            defaultOutputModes=["application/json"],
            capabilities=capabilities,
            skills=[skill],
            authentication=None # No auth for this example
        )
        logger.info(f"Agent Card created for: {agent_card.name}")

        # --- Initialize Task Manager & A2A Server ---
        task_manager = StockInfoTaskManager(mcp_server_script_path=mcp_server_path)
        logger.debug("StockInfoTaskManager initialized.")

        # The A2AServer from common likely takes care of setting up ASGI routes
        # Pass host/port here if the common A2AServer uses them for its internal uvicorn run
        server = A2AServer(
            agent_card=agent_card,
            task_manager=task_manager,
            host=host,
            port=port,
            # endpoint="/a2a" # Specify the endpoint path for A2A methods
        )
        logger.info(f"A2A Server configured to listen on {host}:{port} at endpoint '{server.endpoint}'")

        # --- Start the Server ---
        server.start()

    except ValueError as ve:
         logger.error(f"Configuration error during startup: {ve}")
         click.echo(f"Configuration Error: {ve}", err=True)
    except FileNotFoundError as fnf:
        logger.error(f"File not found error during startup: {fnf}")
        click.echo(f"File Not Found Error: {fnf}", err=True)
    except Exception as e:
        logger.critical(f"An unexpected error occurred during server startup: {e}", exc_info=True)
        click.echo(f"Critical Error: {e}", err=True)

if __name__ == "__main__":
    main()


================================================
FILE: specialist_agents/stock_info_agent/agent.py
================================================
import asyncio
import os
import sys
import logging
from contextlib import AsyncExitStack # Crucial for managing the MCP connection

# --- ADK Imports ---
from google.adk.agents import Agent  # Using the alias
from google.adk.runners import Runner
from google.adk.sessions import InMemorySessionService
from google.genai import types as genai_types # Use alias to avoid confusion

# --- MCP Client Imports ---
# Import the toolset and connection parameters from ADK's MCP integration
from google.adk.tools.mcp_tool.mcp_toolset import MCPToolset, StdioServerParameters

# --- Environment Loading (Optional but recommended) ---
from dotenv import load_dotenv
# Load .env file from the parent directory (live-agent-project)
dotenv_path = os.path.join(os.path.dirname(__file__), '..', '..', '.env')
print(f"dotenv_path: {dotenv_path}")
load_dotenv(dotenv_path=dotenv_path, override=True)


# --- Logging Setup ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# In specialist_agents/stock_info_agent/agent.py, after load_dotenv:
logger.info(f"--- Loaded Environment Variables ---")
logger.info(f"VERTEX_AI?: {os.getenv('GOOGLE_GENAI_USE_VERTEXAI')}")
logger.info(f"PROJECT_ID: {os.getenv('GOOGLE_CLOUD_PROJECT')}")
logger.info(f"LOCATION:   {os.getenv('GOOGLE_CLOUD_LOCATION')}")
logger.info(f"---------------------------------")

# --- Constants ---
APP_NAME = "stock_info_adk_app"
USER_ID = "test_user_stock"
SESSION_ID = "session_stock_001"
MODEL = os.getenv('STOCK_INFO_AGENT_MODEL', "gemini-2.0-flash-001")

# --- MCP Tool Loading Function ---
async def get_mcp_tools_async(mcp_server_script_path: str) -> tuple[list, AsyncExitStack]:
    """
    Connects to the MCP server via stdio and retrieves its tools.

    Args:
        mcp_server_script_path: The absolute path to the MCP server Python script.

    Returns:
        A tuple containing the list of ADK-compatible tools and the AsyncExitStack
        for managing the connection lifecycle.
    """
    logger.info(f"Attempting to connect to MCP server via stdio: {mcp_server_script_path}")
    try:
        # Configure parameters to launch the MCP server script via stdio
        connection_params = StdioServerParameters(
            command=sys.executable,  # Use the current Python interpreter
            args=[mcp_server_script_path], # Pass the script path as an argument
            # Add cwd if necessary, depending on how server.py resolves things
            # cwd=os.path.dirname(mcp_server_script_path)
        )

        # Use ADK's MCPToolset to connect and get tools
        # This starts the server.py script as a subprocess
        tools, exit_stack = await MCPToolset.from_server(
            connection_params=connection_params
        )
        logger.info(f"Successfully connected to MCP server and retrieved {len(tools)} tool(s).")
        return tools, exit_stack
    except Exception as e:
        logger.error(f"Failed to connect to MCP server or get tools: {e}", exc_info=True)
        raise # Re-raise the exception to stop execution if connection fails

# --- ADK Agent Definition Function ---
async def create_agent_with_mcp_tools(mcp_server_script_path: str) -> tuple[Agent, AsyncExitStack]:
    """
    Creates the ADK Agent, equipping it with tools loaded from the MCP server.

    Args:
        mcp_server_script_path: Absolute path to the MCP server script.

    Returns:
        A tuple containing the configured ADK Agent instance and the AsyncExitStack.
    """
    mcp_tools, exit_stack = await get_mcp_tools_async(mcp_server_script_path)

    # Define the ADK Agent that will use the MCP tool(s)
    stock_info_agent = Agent(
        name="stock_info_agent",
        model=MODEL,
        description="Provides current stock price information using an external tool.",
        instruction="You are an assistant that provides stock prices. "
                    "When asked for the price of a stock, use the 'get_current_stock_price' tool. "
                    "The tool takes a 'symbol' argument (e.g., 'MSFT'). "
                    "The tool returns a dictionary with 'price' and 'currency', or an 'error'. "
                    "Relay the information clearly to the user. If the tool returns an error, state that.",
        # Provide the tools loaded from the MCP server to the ADK agent
        tools=mcp_tools,
    )
    logger.info(f"ADK Agent '{stock_info_agent.name}' created with MCP tools.")
    return stock_info_agent, exit_stack



================================================
FILE: specialist_agents/stock_info_agent/task_manager.py
================================================
import os
import logging
import json
from typing import Union, AsyncIterable # <--- Import these

from google.adk.agents import Agent # Import ADK Agent
from google.adk.runners import Runner # Import ADK Runner
from google.adk.sessions import InMemorySessionService, Session # Need Session components
from google.genai import types as genai_types # For Content/Part

from common.server.task_manager import InMemoryTaskManager # Use the base class
from common.types import (
    SendTaskRequest, SendTaskResponse, Task, TaskState, TaskStatus,
    Artifact, TextPart, DataPart, JSONRPCError, InternalError,
    SendTaskStreamingRequest, SendTaskStreamingResponse, # <--- Import these
    UnsupportedOperationError, JSONRPCResponse # <--- Import these
)


from .agent import create_agent_with_mcp_tools
from mcp.types import TextContent, CallToolResult



logger = logging.getLogger(__name__)

class StockInfoTaskManager(InMemoryTaskManager):
    """Handles A2A tasks by running the ADK StockInfoAgent."""

    def __init__(self, mcp_server_script_path: str):
        super().__init__()
        # Store the path needed by create_agent_with_mcp_tools
        self.mcp_server_script_path = mcp_server_script_path
        logger.info(f"StockInfoTaskManager initialized (ADK Runner Mode). Will use MCP server at: {self.mcp_server_script_path}")
        # NOTE: Agent and Runner are now created PER request in this model

    async def on_send_task(self, request: SendTaskRequest) -> SendTaskResponse:
        """Handles A2A task by instantiating and running the ADK agent."""
        task_params = request.params
        task_id = task_params.id
        session_id = task_params.sessionId
        input_message = task_params.message

        logger.info(f"A2A Task Mgr (ADK Mode): Received task '{task_id}' in session '{session_id}'")

        # 1. Create/Update Task State (same as before)
        task = await self.upsert_task(task_params)
        task.status.state = TaskState.WORKING
        await self.update_store(task_id, task.status, None)
        logger.debug(f"A2A Task Mgr (ADK Mode): Task '{task_id}' state set to WORKING.")

        # 2. Extract Symbol (same as before)
        symbol = None
        if input_message.parts:
            for part in input_message.parts:
                if isinstance(part, TextPart) and part.text:
                    symbol = part.text.strip()
                    logger.info(f"A2A Task Mgr (ADK Mode): Extracted symbol '{symbol}' for task '{task_id}'.")
                    break
        if not symbol:
            # Handle error (same as before)
            logger.error(f"A2A Task Mgr (ADK Mode): No symbol found for task '{task_id}'.")
            task.status.state = TaskState.FAILED
            error_artifact = Artifact(name="error_details", parts=[DataPart(data={"error": "Ticker symbol not provided."})])
            task.artifacts = [error_artifact]
            await self.update_store(task_id, task.status, task.artifacts)
            return SendTaskResponse(id=request.id, result=task)

        # --- 3. Run the ADK Agent ---
        adk_agent: Agent | None = None
        exit_stack = None
        adk_result_dict: Dict[str, Any] = {"error": "ADK agent execution failed to produce a result."} # Default error

        try:
            # --- Instantiate ADK components for this request ---
            logger.info(f"A2A Task Mgr (ADK Mode): Creating ADK Agent for task '{task_id}'...")
            # This starts the MCP server subprocess and gets the exit_stack
            adk_agent, exit_stack = await create_agent_with_mcp_tools(self.mcp_server_script_path)

            # Use a transient session service and session for this specific ADK run
            temp_session_service = InMemorySessionService()
            temp_adk_session = temp_session_service.create_session(
                app_name=f"adk_task_{task_id}", # Unique app name per task
                user_id=f"a2a_user_{session_id}",
                session_id=f"adk_run_{task_id}",
                state={} # Start with empty state for the ADK agent run
            )

            adk_runner = Runner(
                agent=adk_agent,
                app_name=temp_adk_session.app_name,
                session_service=temp_session_service,
            )
            logger.info(f"A2A Task Mgr (ADK Mode): ADK Runner initialized for agent '{adk_agent.name}'.")

            # Prepare the input specifically for the ADK agent's tool
            # The ADK agent expects a natural language query that will trigger the tool
            adk_query = f"What is the stock price for {symbol}?"
            adk_content = genai_types.Content(role='user', parts=[genai_types.Part(text=adk_query)])

            logger.info(f"A2A Task Mgr (ADK Mode): Running ADK agent for task '{task_id}'...")
            async for event in adk_runner.run_async(
                session_id=temp_adk_session.id,
                user_id=temp_adk_session.user_id,
                new_message=adk_content
            ):
                 logger.debug(f"A2A Task Mgr (ADK Mode): ADK Event: {event.author} - Final: {event.is_final_response()}")
                 # We need to extract the *tool result* that the agent processed
                 # The final response *from the ADK agent* isn't directly what the A2A server should return.
                 if event.get_function_responses():
                     for func_resp in event.get_function_responses():
                          # Check the tool name is the one we expect
                          if func_resp.name == "get_current_stock_price":
                               try:
                                   # 1. Get the outer dictionary
                                   response_wrapper = func_resp.response
                                   if not isinstance(response_wrapper, dict):
                                        logger.error(f"A2A Task Mgr (ADK Mode): Outer response wasn't a dict: {type(response_wrapper)}")
                                        adk_result_dict = {"error": "Invalid outer tool response format from ADK Agent run."}
                                        break

                                   # 2. Access the nested 'result' which should hold the CallToolResult object (or similar structure)
                                   # Use .get() for safety
                                   mcp_tool_result_obj = response_wrapper.get("result")
                                   if mcp_tool_result_obj is None:
                                        logger.error(f"A2A Task Mgr (ADK Mode): Outer response dict missing 'result' key: {response_wrapper}")
                                        adk_result_dict = {"error": "Missing 'result' in outer tool response format."}
                                        break

                                   # 3. Check if the MCP tool reported an error via the isError attribute
                                   # Access attributes safely using getattr
                                   is_error = getattr(mcp_tool_result_obj, 'isError', False)
                                   mcp_content = getattr(mcp_tool_result_obj, 'content', None)

                                   if is_error:
                                       error_text = "Unknown MCP tool error"
                                       if mcp_content and len(mcp_content) > 0:
                                           # Check if the first content part has 'text'
                                           first_content_part = mcp_content[0]
                                           error_text = getattr(first_content_part, 'text', str(first_content_part))
                                           try: # Try parsing JSON error from tool's text content
                                               parsed_error = json.loads(error_text)
                                               if isinstance(parsed_error, dict) and "error" in parsed_error:
                                                   adk_result_dict = parsed_error # Use the tool's error dict
                                               else:
                                                   adk_result_dict = {"error": f"MCP Tool Error: {error_text}"}
                                           except (json.JSONDecodeError, TypeError): # Catch TypeError just in case
                                                adk_result_dict = {"error": f"MCP Tool Error: {error_text}"} # Treat raw text as error
                                       else:
                                            adk_result_dict = {"error": "MCP Tool reported error with no content."}
                                       logger.error(f"A2A Task Mgr (ADK Mode): MCP Tool reported error: {adk_result_dict}")

                                   # 4. If not an error, extract and parse the JSON from TextContent
                                   elif mcp_content and len(mcp_content) > 0:
                                       first_content_part = mcp_content[0]
                                       # Check it has 'type' == 'text' and a 'text' attribute
                                       if getattr(first_content_part, 'type', None) == 'text' and hasattr(first_content_part, 'text'):
                                            result_text = getattr(first_content_part, 'text', '')
                                            try:
                                                parsed_dict = json.loads(result_text)
                                                if isinstance(parsed_dict, dict) and "price" in parsed_dict and "symbol" in parsed_dict:
                                                    adk_result_dict = parsed_dict # Successfully parsed the result
                                                    logger.info(f"A2A Task Mgr (ADK Mode): Successfully captured tool result: {adk_result_dict}")
                                                else:
                                                    logger.error(f"A2A Task Mgr (ADK Mode): Parsed JSON from tool lacks expected keys: {parsed_dict}")
                                                    adk_result_dict = {"error": "Invalid data structure from MCP tool (missing keys)."}
                                            except json.JSONDecodeError:
                                                logger.error(f"A2A Task Mgr (ADK Mode): Failed to parse JSON from successful MCP tool response text: {result_text}")
                                                adk_result_dict = {"error": "Non-JSON success response text from MCP tool."}
                                       else:
                                           logger.error(f"A2A Task Mgr (ADK Mode): Expected TextContent, but got different type or missing text: {first_content_part}")
                                           adk_result_dict = {"error": "Unexpected content type in successful MCP response."}
                                   else:
                                       # Handle unexpected successful response format (no content)
                                       logger.error(f"A2A Task Mgr (ADK Mode): Successful MCP response has no content: {mcp_tool_result_obj}")
                                       adk_result_dict = {"error": "Missing content in successful MCP response."}

                                   break # Processed the relevant function response

                               except Exception as process_err:
                                    logger.error(f"A2A Task Mgr (ADK Mode): Error processing ADK tool response event: {process_err}", exc_info=True)
                                    adk_result_dict = {"error": "Internal error processing specialist response."}
                                    break # Stop processing on error
                               
            logger.info(f"A2A Task Mgr (ADK Mode): ADK agent run finished for task '{task_id}'.")

        except Exception as adk_err:
            logger.exception(f"A2A Task Mgr (ADK Mode): Error during ADK agent execution for task '{task_id}': {adk_err}")
            adk_result_dict = {"error": f"Failed to execute ADK agent: {str(adk_err)}"}
        finally:
            # --- CRUCIAL: Cleanup the exit_stack for the MCP process ---
            if exit_stack:
                logger.info(f"A2A Task Mgr (ADK Mode): Cleaning up MCP connection for task '{task_id}'...")
                await exit_stack.aclose()
                logger.info(f"A2A Task Mgr (ADK Mode): MCP connection closed for task '{task_id}'.")

        # --- 4. Process Result and Finalize A2A Task ---
        if "error" not in adk_result_dict and "price" in adk_result_dict:
            task.status.state = TaskState.COMPLETED
            task.status.message = None
            result_artifact = Artifact(name="stock_price_data", parts=[DataPart(data=adk_result_dict)])
            task.artifacts = [result_artifact]
            logger.info(f"A2A Task Mgr (ADK Mode): Task '{task_id}' COMPLETED successfully.")
        else:
            task.status.state = TaskState.FAILED
            task.status.message = None
            error_msg = adk_result_dict.get("error", "Unknown error from ADK Agent execution.")
            logger.error(f"A2A Task Mgr (ADK Mode): Task '{task_id}' FAILED. Reason: {error_msg}")
            error_artifact = Artifact(name="error_details", parts=[DataPart(data={"error": error_msg})])
            task.artifacts = [error_artifact]

        await self.update_store(task_id, task.status, task.artifacts)

        # 5. Return A2A Response
        return SendTaskResponse(id=request.id, result=task)
    
    async def on_send_task_subscribe(
        self, request: SendTaskStreamingRequest
    ) -> Union[AsyncIterable[SendTaskStreamingResponse], JSONRPCResponse]:
        """Handles streaming requests - intentionally not supported by this agent."""
        task_id = request.params.id if request.params else "unknown"
        logger.warning(f"A2A Task Manager: Received 'tasks/sendSubscribe' request for task {task_id}, but streaming is not supported by this agent.")
        # Log the incoming request
        logger.info(f"A2A Task Manager: Received Full Request (sendSubscribe): {request.model_dump_json(indent=2)}")
        # Return an error compliant with JSON-RPC and A2A types
        response = JSONRPCResponse(
            id=request.id,
            error=UnsupportedOperationError(
                message="Streaming (tasks/sendSubscribe) is not supported by this agent."
            )
        )
        logger.warning(f"A2A Task Manager: Sending UnsupportedOperation Error Response: {response.model_dump_json(indent=2)}")
        return response

    # Override other handlers as needed, e.g., return "Unsupported" error
    # async def on_get_task(...) -> GetTaskResponse: ...
    # async def on_cancel_task(...) -> CancelTaskResponse: ...
    # async def on_send_task_subscribe(...) -> ... : # Return UnsupportedOperationError


================================================
FILE: tests/test_a2a_stock_client.py
================================================
# tests/test_a2a_stock_client.py
import sys
import os

# Add the project root to the Python path
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

import asyncio
import argparse
import uuid
import logging
import json
from typing import Optional

from common.client import A2AClient
from common.types import (
    TaskSendParams, Message, TextPart, SendTaskResponse, TaskState, Artifact,
    DataPart, A2AClientHTTPError, A2AClientJSONError
)

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - A2A_TEST_CLIENT - %(message)s')
logger = logging.getLogger(__name__)

async def run_a2a_test(symbol: str, server_url: str, session_id: Optional[str] = None):
    """
    Sends a task to the StockInfoAgent A2A server and prints the result.
    """
    if not session_id:
        session_id = f"test_session_{uuid.uuid4().hex[:8]}"
        logger.info(f"No session ID provided, generated one: {session_id}")

    task_id = uuid.uuid4().hex
    logger.info(f"Creating A2A task {task_id} for session {session_id} with symbol '{symbol}'")

    # Create the A2A client targeting the StockInfoAgent server
    a2a_client = A2AClient(url=server_url) # Pass the URL directly

    # Construct the A2A TaskSendParams
    task_params = TaskSendParams(
        id=task_id,
        sessionId=session_id,
        message=Message(
            role="user",
            parts=[TextPart(text=symbol)] # Send the symbol as text
        ),
        # acceptedOutputModes=["application/json"] # Optional: Specify expected output
    )

    logger.info(f"Sending task to A2A server at {server_url}...")

    try:
        # Send the task using the A2A client
        # Use .model_dump() for Pydantic v2+ or .dict() for v1
        response: SendTaskResponse = await a2a_client.send_task(task_params.model_dump())

        logger.info("Received response from A2A server.")

        # Process the response
        if response.error:
            logger.error(f"A2A Server returned an error: {response.error.model_dump()}")
        elif response.result:
            task_result = response.result
            logger.info(f"Task {task_result.id} final state: {task_result.status.state}")

            if task_result.status.state == TaskState.COMPLETED:
                logger.info("Task completed successfully.")
                if task_result.artifacts:
                    logger.info("Artifacts received:")
                    for artifact in task_result.artifacts:
                        logger.info(f"- Artifact Name: {artifact.name or 'N/A'}")
                        for part in artifact.parts:
                            if isinstance(part, DataPart):
                                logger.info(f"  DataPart Content: {json.dumps(part.data, indent=2)}")
                            elif isinstance(part, TextPart):
                                 logger.info(f"  TextPart Content: {part.text}")
                            else:
                                 logger.info(f"  Other Part Type: {part.type}")
                else:
                    logger.warning("Task completed but no artifacts found.")

            elif task_result.status.state == TaskState.FAILED:
                logger.error("Task failed.")
                if task_result.artifacts:
                     logger.error("Error details from artifact:")
                     for artifact in task_result.artifacts:
                         if artifact.name == "error_details":
                             for part in artifact.parts:
                                 if isinstance(part, DataPart):
                                     logger.error(f"  {json.dumps(part.data, indent=2)}")
                                 else:
                                      logger.error(f"  Unexpected error artifact part: {part}")
                elif task_result.status.message:
                     logger.error(f"Error message from status: {task_result.status.message}")
                else:
                     logger.error("Task failed with no specific error details provided.")
            else:
                logger.warning(f"Task ended in unexpected state: {task_result.status.state}")

        else:
            logger.error("Received an empty response from the server.")

    except A2AClientHTTPError as http_err:
        logger.error(f"HTTP Error connecting to A2A server: {http_err.status_code} - {http_err.message}")
    except A2AClientJSONError as json_err:
         logger.error(f"JSON Error processing A2A server response: {json_err.message}")
    except ConnectionRefusedError:
         logger.error(f"Connection refused. Is the A2A server running at {server_url}?")
    except Exception as e:
        logger.error(f"An unexpected error occurred: {e}", exc_info=True)

# --- Script Entry Point ---
if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Test client for the StockInfoAgent A2A server.")
    parser.add_argument("symbol", help="The stock ticker symbol to query (e.g., MSFT).")
    parser.add_argument("--url", default="http://127.0.0.1:8001", help="The full URL of the A2A server endpoint.")
    parser.add_argument("--session", default=None, help="Optional session ID to use.")

    args = parser.parse_args()

    try:
        asyncio.run(run_a2a_test(args.symbol, args.url, args.session))
    except KeyboardInterrupt:
        logger.info("Test client stopped by user.")

